# Milestone 0.11.0 — Feature Parity Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement Track Manifest, Video Sync, Waveform Editor, Format Conversion, improved OCR, and Quality Fixes to reach feature parity with Bazarr, TinyMM, and SubtitleEdit.

**Architecture:** Seven self-contained phases, each adding new API endpoints and frontend components. All phases are additive — no existing endpoints change. Backend follows the existing Blueprint pattern (`routes/*.py`), job pattern (`db/jobs.py`), and path-mapping convention (`map_path()`).

**Tech Stack:** Flask (Blueprint API), pysubs2, ffmpeg, ffsubsync, alass, wavesurfer.js, pyhunspell, Tesseract, React 19 + TypeScript + Tailwind v4

---

## Phase 29 — Track Manifest

### Task 29-1: Backend route file

**Files:**
- Create: `backend/routes/tracks.py`
- Modify: `backend/routes/__init__.py`

**Step 1: Create `backend/routes/tracks.py`**

```python
"""Track manifest routes — list, extract, and use embedded subtitle tracks.

GET  /api/v1/library/episodes/<ep_id>/tracks
POST /api/v1/library/episodes/<ep_id>/tracks/<index>/extract
POST /api/v1/library/episodes/<ep_id>/tracks/<index>/use-as-source
"""

import os
import logging

from flask import Blueprint, request, jsonify

bp = Blueprint("tracks", __name__, url_prefix="/api/v1/library")
logger = logging.getLogger(__name__)


def _get_video_path(ep_id: int) -> tuple[str | None, tuple | None]:
    """Resolve episode ID → mapped local video path.

    Returns:
        (video_path, None) on success
        (None, (error_msg, status_code)) on failure
    """
    from config import get_settings, map_path
    from database import get_db, _db_lock

    with _db_lock:
        conn = get_db()
        row = conn.execute(
            "SELECT sonarr_episode_id FROM wanted_items WHERE sonarr_episode_id = ? LIMIT 1",
            (ep_id,),
        ).fetchone()

    # Resolve path via Sonarr
    settings = get_settings()
    try:
        from integrations.sonarr import SonarrClient
        sonarr = SonarrClient(settings.sonarr_url, settings.sonarr_api_key)
        ep = sonarr.get_episode(ep_id)
    except Exception as e:
        return None, (f"Could not fetch episode from Sonarr: {e}", 502)

    if not ep or not ep.get("hasFile"):
        return None, ("Episode has no file", 404)

    file_info = ep.get("episodeFile") or {}
    raw_path = file_info.get("path", "")
    if not raw_path:
        # Try episodeFileId lookup
        try:
            ef = sonarr.get_episode_file(ep.get("episodeFileId"))
            raw_path = ef.get("path", "") if ef else ""
        except Exception:
            pass

    if not raw_path:
        return None, ("Could not resolve video file path", 404)

    return map_path(raw_path), None


@bp.route("/episodes/<int:ep_id>/tracks", methods=["GET"])
def list_tracks(ep_id: int):
    """Return all subtitle and audio tracks embedded in the episode's video file."""
    video_path, err = _get_video_path(ep_id)
    if err:
        return jsonify({"error": err[0]}), err[1]

    if not os.path.exists(video_path):
        return jsonify({"error": f"Video file not found: {video_path}"}), 404

    try:
        from ass_utils import get_media_streams
        probe = get_media_streams(video_path, use_cache=True)
    except Exception as e:
        return jsonify({"error": f"Could not probe video: {e}"}), 500

    tracks = []
    for stream in probe.get("streams", []):
        codec_type = stream.get("codec_type", "")
        if codec_type not in ("subtitle", "audio"):
            continue
        tags = stream.get("tags", {})
        disposition = stream.get("disposition", {})
        tracks.append({
            "index": stream.get("index"),
            "codec_type": codec_type,
            "codec": stream.get("codec_name", ""),
            "language": tags.get("language", ""),
            "title": tags.get("title", ""),
            "forced": bool(disposition.get("forced", 0)),
            "default": bool(disposition.get("default", 0)),
        })

    return jsonify({"tracks": tracks, "video_path": video_path})


@bp.route("/episodes/<int:ep_id>/tracks/<int:track_index>/extract", methods=["POST"])
def extract_track(ep_id: int, track_index: int):
    """Extract an embedded subtitle track to a sidecar file next to the video."""
    video_path, err = _get_video_path(ep_id)
    if err:
        return jsonify({"error": err[0]}), err[1]

    if not os.path.exists(video_path):
        return jsonify({"error": f"Video file not found: {video_path}"}), 404

    data = request.get_json(silent=True) or {}
    target_lang = data.get("language", "")  # optional override for filename

    try:
        from ass_utils import get_media_streams
        probe = get_media_streams(video_path, use_cache=True)
    except Exception as e:
        return jsonify({"error": f"Could not probe video: {e}"}), 500

    stream = next(
        (s for s in probe.get("streams", []) if s.get("index") == track_index),
        None,
    )
    if not stream:
        return jsonify({"error": f"Track index {track_index} not found"}), 404

    if stream.get("codec_type") != "subtitle":
        return jsonify({"error": "Track is not a subtitle track"}), 400

    codec = stream.get("codec_name", "subrip")
    ext = "ass" if codec in ("ass", "ssa") else "srt"
    lang = target_lang or stream.get("tags", {}).get("language", "und")

    base = os.path.splitext(video_path)[0]
    output_path = f"{base}.{lang}.{ext}"

    try:
        from ass_utils import extract_subtitle_stream
        extract_subtitle_stream(video_path, {"sub_index": track_index, "format": codec}, output_path)
    except Exception as e:
        return jsonify({"error": f"Extraction failed: {e}"}), 500

    logger.info("Extracted track %d from %s → %s", track_index, video_path, output_path)
    return jsonify({"output_path": output_path, "language": lang, "format": ext})


@bp.route("/episodes/<int:ep_id>/tracks/<int:track_index>/use-as-source", methods=["POST"])
def use_track_as_source(ep_id: int, track_index: int):
    """Extract track and return its content for use in the editor or as translation source."""
    video_path, err = _get_video_path(ep_id)
    if err:
        return jsonify({"error": err[0]}), err[1]

    if not os.path.exists(video_path):
        return jsonify({"error": f"Video file not found: {video_path}"}), 404

    try:
        from ass_utils import get_media_streams
        probe = get_media_streams(video_path, use_cache=True)
    except Exception as e:
        return jsonify({"error": f"Could not probe video: {e}"}), 500

    stream = next(
        (s for s in probe.get("streams", []) if s.get("index") == track_index),
        None,
    )
    if not stream or stream.get("codec_type") != "subtitle":
        return jsonify({"error": "Invalid or non-subtitle track"}), 400

    import tempfile
    codec = stream.get("codec_name", "subrip")
    ext = "ass" if codec in ("ass", "ssa") else "srt"

    with tempfile.NamedTemporaryFile(suffix=f".{ext}", delete=False) as tmp:
        tmp_path = tmp.name

    try:
        from ass_utils import extract_subtitle_stream
        extract_subtitle_stream(video_path, {"sub_index": track_index, "format": codec}, tmp_path)
        with open(tmp_path, "r", encoding="utf-8", errors="replace") as f:
            content = f.read()
    except Exception as e:
        return jsonify({"error": f"Extraction failed: {e}"}), 500
    finally:
        try:
            os.unlink(tmp_path)
        except OSError:
            pass

    return jsonify({
        "content": content,
        "format": ext,
        "language": stream.get("tags", {}).get("language", ""),
        "title": stream.get("tags", {}).get("title", ""),
    })
```

**Step 2: Register blueprint in `backend/routes/__init__.py`**

Add at the end of the import block:
```python
from routes.tracks import bp as tracks_bp
```
Add `tracks_bp` to the `for blueprint in [...]` list.

**Step 3: Write tests**

```python
# backend/tests/test_tracks.py
import pytest
from unittest.mock import patch, MagicMock


FAKE_PROBE = {"streams": [
    {"index": 2, "codec_type": "subtitle", "codec_name": "ass",
     "tags": {"language": "jpn", "title": "Japanese"}, "disposition": {"forced": 0, "default": 1}},
    {"index": 3, "codec_type": "subtitle", "codec_name": "subrip",
     "tags": {"language": "eng", "title": ""}, "disposition": {"forced": 0, "default": 0}},
    {"index": 1, "codec_type": "audio", "codec_name": "aac",
     "tags": {"language": "jpn", "title": ""}, "disposition": {}},
]}


def test_list_tracks_returns_all_subtitle_and_audio(client):
    with patch("routes.tracks._get_video_path", return_value=("/media/ep.mkv", None)), \
         patch("os.path.exists", return_value=True), \
         patch("ass_utils.get_media_streams", return_value=FAKE_PROBE):
        r = client.get("/api/v1/library/episodes/1/tracks")
    assert r.status_code == 200
    tracks = r.get_json()["tracks"]
    assert len(tracks) == 3
    assert tracks[0]["codec"] == "ass"
    assert tracks[0]["language"] == "jpn"
    assert tracks[0]["forced"] is False


def test_list_tracks_404_when_no_file(client):
    with patch("routes.tracks._get_video_path", return_value=(None, ("Episode has no file", 404))):
        r = client.get("/api/v1/library/episodes/99/tracks")
    assert r.status_code == 404


def test_extract_track_success(client, tmp_path):
    fake_output = str(tmp_path / "ep.jpn.ass")
    with patch("routes.tracks._get_video_path", return_value=("/media/ep.mkv", None)), \
         patch("os.path.exists", return_value=True), \
         patch("ass_utils.get_media_streams", return_value=FAKE_PROBE), \
         patch("ass_utils.extract_subtitle_stream") as mock_extract, \
         patch("os.path.splitext", return_value=("/media/ep", ".mkv")):
        r = client.post("/api/v1/library/episodes/1/tracks/2/extract",
                        json={"language": "jpn"})
    assert r.status_code == 200
    assert r.get_json()["format"] == "ass"
    mock_extract.assert_called_once()
```

**Step 4: Run tests**

```bash
cd backend && python -m pytest tests/test_tracks.py -v
```

**Step 5: Commit**

```bash
git add backend/routes/tracks.py backend/routes/__init__.py backend/tests/test_tracks.py
git commit -m "feat(phase-29): track manifest backend — list/extract/use-as-source"
```

---

### Task 29-2: Frontend — TrackPanel component

**Files:**
- Create: `frontend/src/components/tracks/TrackPanel.tsx`
- Modify: `frontend/src/api/client.ts`
- Modify: `frontend/src/pages/SeriesDetail.tsx`

**Step 1: Add API calls to `frontend/src/api/client.ts`**

```typescript
export const listEpisodeTracks = (epId: number) =>
  apiClient.get<{ tracks: Track[]; video_path: string }>(
    `/library/episodes/${epId}/tracks`
  );

export const extractTrack = (epId: number, index: number, language?: string) =>
  apiClient.post<{ output_path: string; language: string; format: string }>(
    `/library/episodes/${epId}/tracks/${index}/extract`,
    { language }
  );

export const useTrackAsSource = (epId: number, index: number) =>
  apiClient.post<{ content: string; format: string; language: string; title: string }>(
    `/library/episodes/${epId}/tracks/${index}/use-as-source`,
    {}
  );
```

Add the `Track` type to the types file:
```typescript
// frontend/src/types/index.ts
export interface Track {
  index: number;
  codec_type: "subtitle" | "audio";
  codec: string;
  language: string;
  title: string;
  forced: boolean;
  default: boolean;
}
```

**Step 2: Create `frontend/src/components/tracks/TrackPanel.tsx`**

```tsx
import { useState } from "react";
import { Track } from "@/types";
import { listEpisodeTracks, extractTrack, useTrackAsSource } from "@/api/client";

interface Props {
  episodeId: number;
  onUseAsSource?: (content: string, format: string, language: string) => void;
}

const CODEC_LABELS: Record<string, string> = {
  ass: "ASS", ssa: "SSA", subrip: "SRT",
  hdmv_pgs_subtitle: "PGS", dvd_subtitle: "VobSub",
  webvtt: "VTT", aac: "AAC", ac3: "AC3", dts: "DTS",
};

export function TrackPanel({ episodeId, onUseAsSource }: Props) {
  const [open, setOpen] = useState(false);
  const [tracks, setTracks] = useState<Track[] | null>(null);
  const [loading, setLoading] = useState(false);
  const [extracting, setExtracting] = useState<number | null>(null);
  const [error, setError] = useState<string | null>(null);

  const load = async () => {
    if (tracks) { setOpen(o => !o); return; }
    setLoading(true);
    setError(null);
    try {
      const res = await listEpisodeTracks(episodeId);
      setTracks(res.data.tracks);
      setOpen(true);
    } catch {
      setError("Tracks konnten nicht geladen werden");
    } finally {
      setLoading(false);
    }
  };

  const handleExtract = async (track: Track) => {
    setExtracting(track.index);
    try {
      await extractTrack(episodeId, track.index, track.language);
    } finally {
      setExtracting(null);
    }
  };

  const handleUseAsSource = async (track: Track) => {
    setExtracting(track.index);
    try {
      const res = await useTrackAsSource(episodeId, track.index);
      onUseAsSource?.(res.data.content, res.data.format, res.data.language);
    } finally {
      setExtracting(null);
    }
  };

  const subtitleTracks = tracks?.filter(t => t.codec_type === "subtitle") ?? [];
  const audioTracks = tracks?.filter(t => t.codec_type === "audio") ?? [];

  return (
    <div className="mt-1">
      <button
        onClick={load}
        className="text-xs text-zinc-400 hover:text-zinc-200 flex items-center gap-1"
        disabled={loading}
      >
        {loading ? "Laden…" : open ? "▾ Tracks" : "▸ Tracks"}
      </button>

      {error && <p className="text-xs text-red-400 mt-1">{error}</p>}

      {open && tracks && (
        <div className="mt-2 space-y-1 pl-2 border-l border-zinc-700">
          {subtitleTracks.length > 0 && (
            <>
              <p className="text-xs text-zinc-500 uppercase tracking-wide">Untertitel</p>
              {subtitleTracks.map(t => (
                <div key={t.index} className="flex items-center gap-2 text-xs">
                  <span className="text-zinc-300 w-8">{t.language || "?"}</span>
                  <span className="bg-zinc-700 px-1 rounded text-zinc-300">
                    {CODEC_LABELS[t.codec] ?? t.codec.toUpperCase()}
                  </span>
                  {t.forced && (
                    <span className="bg-amber-900/50 text-amber-300 px-1 rounded">forced</span>
                  )}
                  {t.title && <span className="text-zinc-500 truncate max-w-[120px]">{t.title}</span>}
                  <button
                    onClick={() => handleExtract(t)}
                    disabled={extracting === t.index}
                    className="ml-auto text-zinc-400 hover:text-zinc-200"
                  >
                    Extrahieren
                  </button>
                  {onUseAsSource && (
                    <button
                      onClick={() => handleUseAsSource(t)}
                      disabled={extracting === t.index}
                      className="text-blue-400 hover:text-blue-200"
                    >
                      Als Quelle
                    </button>
                  )}
                </div>
              ))}
            </>
          )}
          {audioTracks.length > 0 && (
            <>
              <p className="text-xs text-zinc-500 uppercase tracking-wide mt-2">Audio</p>
              {audioTracks.map(t => (
                <div key={t.index} className="flex items-center gap-2 text-xs text-zinc-400">
                  <span className="w-8">{t.language || "?"}</span>
                  <span className="bg-zinc-800 px-1 rounded">
                    {CODEC_LABELS[t.codec] ?? t.codec.toUpperCase()}
                  </span>
                  {t.title && <span className="truncate max-w-[120px]">{t.title}</span>}
                </div>
              ))}
            </>
          )}
        </div>
      )}
    </div>
  );
}
```

**Step 3: Integrate TrackPanel in SeriesDetail episode rows**

In `frontend/src/pages/SeriesDetail.tsx`, find the episode row rendering.
Import `TrackPanel` and add it below the subtitle badges per episode:

```tsx
import { TrackPanel } from "@/components/tracks/TrackPanel";

// Inside episode row, after subtitle badges:
{ep.has_file && (
  <TrackPanel
    episodeId={ep.id}
    onUseAsSource={(content, format, lang) => {
      // Open editor with this content as the source
      openEditor(ep, content, format, lang);
    }}
  />
)}
```

**Step 4: Commit**

```bash
git add frontend/src/components/tracks/ frontend/src/api/client.ts frontend/src/pages/SeriesDetail.tsx
git commit -m "feat(phase-29): track manifest frontend — TrackPanel with extract and use-as-source"
```

---

## Phase 30 — Video Sync Backend

### Task 30-1: Service + routes

**Files:**
- Create: `backend/services/video_sync.py`
- Create: `backend/routes/video_sync.py`
- Modify: `backend/routes/__init__.py`
- Modify: `backend/requirements.txt`
- Modify: `Dockerfile`

**Step 1: Add dependencies to `backend/requirements.txt`**

```
# Optional — video sync engines (graceful degradation if missing)
ffsubsync>=0.4.26
alass-cli>=0.1.0
```

**Step 2: Add to `Dockerfile` (in pip install layer)**

```dockerfile
RUN pip install --no-cache-dir -r requirements.txt || true
```
Already handled since requirements.txt is installed. No Dockerfile change needed — both are pip packages.

**Step 3: Create `backend/services/video_sync.py`**

```python
"""Video subtitle synchronization service.

Wraps ffsubsync and alass CLI tools. Both are optional dependencies —
SyncUnavailableError is raised when an engine is not installed.
"""

import os
import shutil
import logging
import subprocess
import tempfile

logger = logging.getLogger(__name__)

FFSUBSYNC_AVAILABLE = bool(shutil.which("ffsubsync") or _check_module("ffsubsync"))
ALASS_AVAILABLE = bool(shutil.which("alass"))


def _check_module(name: str) -> bool:
    try:
        __import__(name)
        return True
    except ImportError:
        return False


class SyncUnavailableError(Exception):
    """Raised when the requested sync engine is not installed."""


def sync_with_ffsubsync(subtitle_path: str, video_path: str) -> dict:
    """Sync subtitle to video using ffsubsync (speech-detection based).

    Args:
        subtitle_path: Path to the subtitle file to sync (modified in-place after backup)
        video_path: Path to the video file

    Returns:
        dict with keys: output_path, shift_ms (approximate), engine

    Raises:
        SyncUnavailableError: ffsubsync not installed
        RuntimeError: ffsubsync failed
    """
    if not FFSUBSYNC_AVAILABLE:
        raise SyncUnavailableError(
            "ffsubsync is not installed. Install with: pip install ffsubsync"
        )

    # Backup original
    backup = _make_backup(subtitle_path)
    logger.info("ffsubsync: syncing %s against %s (backup: %s)",
                subtitle_path, video_path, backup)

    with tempfile.NamedTemporaryFile(
        suffix=os.path.splitext(subtitle_path)[1], delete=False
    ) as tmp:
        out_path = tmp.name

    cmd = ["ffsubsync", video_path, "-i", subtitle_path, "-o", out_path]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
    except subprocess.TimeoutExpired:
        raise RuntimeError("ffsubsync timed out after 600s")

    if result.returncode != 0:
        raise RuntimeError(f"ffsubsync failed: {result.stderr.strip()}")

    # Replace original with synced version
    shutil.move(out_path, subtitle_path)

    shift_ms = _parse_ffsubsync_shift(result.stderr + result.stdout)
    logger.info("ffsubsync: done, estimated shift %dms", shift_ms)

    return {"output_path": subtitle_path, "shift_ms": shift_ms, "engine": "ffsubsync",
            "backup_path": backup}


def sync_with_alass(subtitle_path: str, reference_path: str) -> dict:
    """Sync subtitle to a reference subtitle using alass.

    Args:
        subtitle_path: Path to the subtitle file to sync
        reference_path: Path to the reference subtitle (e.g. extracted from MKV)

    Returns:
        dict with keys: output_path, engine, backup_path

    Raises:
        SyncUnavailableError: alass not installed
        RuntimeError: alass failed
    """
    if not ALASS_AVAILABLE:
        raise SyncUnavailableError(
            "alass is not installed. Install from: https://github.com/kaegi/alass"
        )

    backup = _make_backup(subtitle_path)
    logger.info("alass: syncing %s against %s", subtitle_path, reference_path)

    with tempfile.NamedTemporaryFile(
        suffix=os.path.splitext(subtitle_path)[1], delete=False
    ) as tmp:
        out_path = tmp.name

    cmd = ["alass", reference_path, subtitle_path, out_path]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
    except subprocess.TimeoutExpired:
        raise RuntimeError("alass timed out after 300s")

    if result.returncode != 0:
        raise RuntimeError(f"alass failed: {result.stderr.strip()}")

    shutil.move(out_path, subtitle_path)
    logger.info("alass: sync complete")

    return {"output_path": subtitle_path, "engine": "alass", "backup_path": backup}


def _make_backup(file_path: str) -> str:
    """Copy file to <base>.bak<ext> and return backup path."""
    base, ext = os.path.splitext(file_path)
    backup = f"{base}.bak{ext}"
    shutil.copy2(file_path, backup)
    return backup


def _parse_ffsubsync_shift(output: str) -> int:
    """Extract offset in ms from ffsubsync output. Returns 0 if not found."""
    import re
    m = re.search(r"offset.*?([-\d.]+)\s*s", output, re.IGNORECASE)
    if m:
        try:
            return int(float(m.group(1)) * 1000)
        except ValueError:
            pass
    return 0


def get_available_engines() -> dict:
    """Return which sync engines are available."""
    return {
        "ffsubsync": FFSUBSYNC_AVAILABLE,
        "alass": ALASS_AVAILABLE,
    }
```

**Step 4: Create `backend/routes/video_sync.py`**

```python
"""Video sync routes — async subtitle synchronization against video/reference.

POST /api/v1/tools/video-sync        → start sync job, returns job_id
GET  /api/v1/tools/video-sync/<id>   → job status
GET  /api/v1/tools/video-sync/engines → available engines
"""

import os
import logging
import uuid
import threading
from concurrent.futures import ThreadPoolExecutor

from flask import Blueprint, request, jsonify

bp = Blueprint("video_sync", __name__, url_prefix="/api/v1/tools")
logger = logging.getLogger(__name__)

_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="video-sync")
_jobs: dict = {}  # job_id -> {status, result, error}
_jobs_lock = threading.Lock()


def _update_job(job_id: str, status: str, result: dict = None, error: str = None):
    with _jobs_lock:
        _jobs[job_id] = {"status": status, "result": result, "error": error}
    # Emit via Socket.IO if available
    try:
        from app import socketio
        socketio.emit("sync_job_update", {"job_id": job_id, "status": status,
                                           "result": result, "error": error})
    except Exception:
        pass


def _run_sync(job_id: str, engine: str, subtitle_path: str,
              video_path: str | None, reference_path: str | None):
    _update_job(job_id, "running")
    try:
        from services.video_sync import sync_with_ffsubsync, sync_with_alass
        if engine == "ffsubsync":
            result = sync_with_ffsubsync(subtitle_path, video_path)
        elif engine == "alass":
            result = sync_with_alass(subtitle_path, reference_path)
        else:
            raise ValueError(f"Unknown engine: {engine}")
        _update_job(job_id, "completed", result=result)
    except Exception as e:
        logger.exception("Sync job %s failed", job_id)
        _update_job(job_id, "failed", error=str(e))


@bp.route("/video-sync/engines", methods=["GET"])
def get_engines():
    from services.video_sync import get_available_engines
    return jsonify(get_available_engines())


@bp.route("/video-sync", methods=["POST"])
def start_sync():
    """Start an async video sync job."""
    data = request.get_json(force=True, silent=True) or {}
    subtitle_path = data.get("file_path", "")
    video_path = data.get("video_path", "")
    engine = data.get("engine", "ffsubsync")
    reference_track_index = data.get("reference_track_index")
    reference_path = data.get("reference_path", "")  # pre-extracted reference sub

    if not subtitle_path:
        return jsonify({"error": "file_path is required"}), 400
    if not os.path.exists(subtitle_path):
        return jsonify({"error": f"Subtitle file not found: {subtitle_path}"}), 404

    if engine == "ffsubsync" and not video_path:
        return jsonify({"error": "video_path is required for ffsubsync"}), 400
    if engine == "alass" and not (reference_path or reference_track_index is not None):
        return jsonify({"error": "reference_path or reference_track_index required for alass"}), 400

    # If reference_track_index given, extract it to a temp file first
    extracted_ref = None
    if engine == "alass" and reference_track_index is not None and video_path:
        import tempfile
        from ass_utils import get_media_streams, extract_subtitle_stream
        probe = get_media_streams(video_path)
        stream = next(
            (s for s in probe.get("streams", []) if s.get("index") == reference_track_index),
            None,
        )
        if not stream:
            return jsonify({"error": f"Track {reference_track_index} not found"}), 404
        codec = stream.get("codec_name", "subrip")
        ext = "ass" if codec in ("ass", "ssa") else "srt"
        tmp = tempfile.NamedTemporaryFile(suffix=f".{ext}", delete=False)
        tmp.close()
        extract_subtitle_stream(video_path, {"sub_index": reference_track_index, "format": codec},
                                tmp.name)
        extracted_ref = tmp.name
        reference_path = extracted_ref

    job_id = str(uuid.uuid4())
    _update_job(job_id, "queued")
    _executor.submit(_run_sync, job_id, engine, subtitle_path, video_path or None,
                     reference_path or None)

    return jsonify({"job_id": job_id}), 202


@bp.route("/video-sync/<job_id>", methods=["GET"])
def sync_status(job_id: str):
    with _jobs_lock:
        job = _jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404
    return jsonify({"job_id": job_id, **job})
```

**Step 5: Register blueprint in `backend/routes/__init__.py`**

```python
from routes.video_sync import bp as video_sync_bp
# add video_sync_bp to the list
```

**Step 6: Write tests**

```python
# backend/tests/test_video_sync.py
from unittest.mock import patch, MagicMock
import pytest


def test_get_engines(client):
    with patch("services.video_sync.get_available_engines",
               return_value={"ffsubsync": True, "alass": False}):
        r = client.get("/api/v1/tools/video-sync/engines")
    assert r.status_code == 200
    assert "ffsubsync" in r.get_json()


def test_start_sync_missing_file(client):
    r = client.post("/api/v1/tools/video-sync",
                    json={"file_path": "/nonexistent.srt", "video_path": "/v.mkv",
                          "engine": "ffsubsync"})
    assert r.status_code == 404


def test_start_sync_queues_job(client, tmp_path):
    sub = tmp_path / "ep.de.srt"
    sub.write_text("1\n00:00:01,000 --> 00:00:02,000\nHello\n")
    with patch("routes.video_sync._executor") as mock_exec:
        r = client.post("/api/v1/tools/video-sync",
                        json={"file_path": str(sub), "video_path": "/media/ep.mkv",
                              "engine": "ffsubsync"})
    assert r.status_code == 202
    assert "job_id" in r.get_json()
    mock_exec.submit.assert_called_once()


def test_sync_status_not_found(client):
    r = client.get("/api/v1/tools/video-sync/nonexistent-id")
    assert r.status_code == 404
```

**Step 7: Run tests**

```bash
cd backend && python -m pytest tests/test_video_sync.py -v
```

**Step 8: Commit**

```bash
git add backend/services/video_sync.py backend/routes/video_sync.py \
        backend/routes/__init__.py backend/requirements.txt backend/tests/test_video_sync.py
git commit -m "feat(phase-30): video sync backend — ffsubsync + alass with async job API"
```

---

## Phase 31 — Video Sync Frontend + Auto-Sync

### Task 31-1: SyncModal component

**Files:**
- Create: `frontend/src/components/sync/SyncModal.tsx`
- Modify: `frontend/src/api/client.ts`
- Modify: `frontend/src/pages/SeriesDetail.tsx`

**Step 1: Add API calls to `client.ts`**

```typescript
export const getSyncEngines = () =>
  apiClient.get<Record<string, boolean>>("/tools/video-sync/engines");

export const startVideoSync = (params: {
  file_path: string;
  video_path: string;
  engine: "ffsubsync" | "alass";
  reference_track_index?: number;
}) => apiClient.post<{ job_id: string }>("/tools/video-sync", params);

export const getSyncJobStatus = (jobId: string) =>
  apiClient.get<{ status: string; result?: object; error?: string }>(
    `/tools/video-sync/${jobId}`
  );
```

**Step 2: Create `frontend/src/components/sync/SyncModal.tsx`**

```tsx
import { useState, useEffect } from "react";
import { Track } from "@/types";
import { getSyncEngines, startVideoSync, getSyncJobStatus } from "@/api/client";

interface Props {
  episodeId: number;
  subtitlePath: string;
  videoPath: string;
  tracks: Track[];
  onClose: () => void;
  onComplete: () => void;
}

export function SyncModal({ subtitlePath, videoPath, tracks, onClose, onComplete }: Props) {
  const [engines, setEngines] = useState<Record<string, boolean>>({});
  const [engine, setEngine] = useState<"ffsubsync" | "alass">("ffsubsync");
  const [refTrackIdx, setRefTrackIdx] = useState<number | undefined>();
  const [jobId, setJobId] = useState<string | null>(null);
  const [status, setStatus] = useState<string>("idle");
  const [result, setResult] = useState<any>(null);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    getSyncEngines().then(r => setEngines(r.data)).catch(() => {});
  }, []);

  // Poll job status
  useEffect(() => {
    if (!jobId || status === "completed" || status === "failed") return;
    const interval = setInterval(async () => {
      try {
        const r = await getSyncJobStatus(jobId);
        setStatus(r.data.status);
        if (r.data.result) setResult(r.data.result);
        if (r.data.error) setError(r.data.error);
        if (r.data.status === "completed") onComplete();
      } catch {}
    }, 1500);
    return () => clearInterval(interval);
  }, [jobId, status]);

  const subtitleTracks = tracks.filter(t => t.codec_type === "subtitle");

  const handleStart = async () => {
    setError(null);
    setStatus("starting");
    try {
      const r = await startVideoSync({
        file_path: subtitlePath,
        video_path: videoPath,
        engine,
        reference_track_index: engine === "alass" ? refTrackIdx : undefined,
      });
      setJobId(r.data.job_id);
      setStatus("queued");
    } catch (e: any) {
      setError(e?.response?.data?.error ?? "Fehler beim Starten des Sync-Jobs");
      setStatus("idle");
    }
  };

  return (
    <div className="fixed inset-0 bg-black/70 flex items-center justify-center z-50">
      <div className="bg-zinc-900 border border-zinc-700 rounded-lg p-6 w-full max-w-md">
        <h2 className="text-lg font-semibold mb-4">Untertitel synchronisieren</h2>

        <div className="space-y-4">
          <div>
            <label className="text-sm text-zinc-400">Engine</label>
            <div className="flex gap-2 mt-1">
              {(["ffsubsync", "alass"] as const).map(e => (
                <button
                  key={e}
                  onClick={() => setEngine(e)}
                  disabled={!engines[e]}
                  className={`px-3 py-1.5 rounded text-sm border ${
                    engine === e
                      ? "border-blue-500 bg-blue-500/20 text-blue-300"
                      : "border-zinc-700 text-zinc-400"
                  } disabled:opacity-40`}
                >
                  {e}
                  {!engines[e] && <span className="ml-1 text-xs">(nicht installiert)</span>}
                </button>
              ))}
            </div>
          </div>

          {engine === "alass" && (
            <div>
              <label className="text-sm text-zinc-400">Referenz-Track</label>
              <select
                className="mt-1 w-full bg-zinc-800 border border-zinc-700 rounded px-2 py-1.5 text-sm"
                value={refTrackIdx ?? ""}
                onChange={e => setRefTrackIdx(e.target.value ? Number(e.target.value) : undefined)}
              >
                <option value="">— Track wählen —</option>
                {subtitleTracks.map(t => (
                  <option key={t.index} value={t.index}>
                    {t.language} — {t.codec.toUpperCase()}{t.title ? ` (${t.title})` : ""}
                  </option>
                ))}
              </select>
            </div>
          )}

          {error && <p className="text-sm text-red-400">{error}</p>}
          {status !== "idle" && status !== "starting" && (
            <p className="text-sm text-zinc-300">Status: {status}</p>
          )}
          {result && (
            <p className="text-sm text-green-400">
              Sync abgeschlossen
              {result.shift_ms !== undefined ? ` (Versatz: ${result.shift_ms}ms)` : ""}
            </p>
          )}
        </div>

        <div className="flex justify-end gap-2 mt-6">
          <button onClick={onClose} className="px-4 py-2 text-sm text-zinc-400 hover:text-zinc-200">
            Schließen
          </button>
          <button
            onClick={handleStart}
            disabled={status !== "idle" || (engine === "alass" && refTrackIdx === undefined)}
            className="px-4 py-2 text-sm bg-blue-600 hover:bg-blue-500 rounded disabled:opacity-40"
          >
            Starten
          </button>
        </div>
      </div>
    </div>
  );
}
```

**Step 3: Add Sync button to SeriesDetail episode rows**

```tsx
// In episode row actions, next to subtitle badge:
<button
  onClick={() => openSyncModal(ep)}
  className="text-xs text-zinc-400 hover:text-zinc-200"
  title="Untertitel synchronisieren"
>
  Sync
</button>
```

**Step 4: Commit**

```bash
git add frontend/src/components/sync/ frontend/src/api/client.ts frontend/src/pages/SeriesDetail.tsx
git commit -m "feat(phase-31): video sync frontend — SyncModal with engine selector and job polling"
```

---

### Task 31-2: Auto-Sync after download

**Files:**
- Modify: `backend/wanted_search.py`
- Modify: `backend/config.py`

**Step 1: Add settings to `backend/config.py`**

In the `Settings` class:
```python
auto_sync_after_download: bool = False
auto_sync_engine: str = "ffsubsync"  # "ffsubsync" | "alass"
```

**Step 2: Add auto-sync call in `backend/wanted_search.py`**

After a successful subtitle download (find the line where `existing_sub` or download success is logged):

```python
def _try_auto_sync(subtitle_path: str, video_path: str, settings) -> None:
    """Enqueue a sync job if auto_sync_after_download is enabled."""
    if not getattr(settings, "auto_sync_after_download", False):
        return
    engine = getattr(settings, "auto_sync_engine", "ffsubsync")
    try:
        from services.video_sync import sync_with_ffsubsync, sync_with_alass, SyncUnavailableError
        logger.info("Auto-sync: starting %s for %s", engine, subtitle_path)
        if engine == "ffsubsync":
            sync_with_ffsubsync(subtitle_path, video_path)
        else:
            logger.warning("Auto-sync: alass requires a reference track — skipping")
    except SyncUnavailableError as e:
        logger.warning("Auto-sync skipped: %s", e)
    except Exception as e:
        logger.error("Auto-sync failed for %s: %s", subtitle_path, e)
```

Call `_try_auto_sync(subtitle_path, video_path, settings)` immediately after a successful download.

**Step 5: Expose in Settings UI**

In `frontend/src/pages/Settings/TranslationTab.tsx` (or relevant settings tab), add:
```tsx
<ToggleSetting
  label="Auto-Sync nach Download"
  description="Synchronisiert heruntergeladene Untertitel automatisch gegen die Videodatei"
  settingKey="auto_sync_after_download"
/>
<SelectSetting
  label="Auto-Sync Engine"
  settingKey="auto_sync_engine"
  options={[
    { value: "ffsubsync", label: "ffsubsync (Sprach-Erkennung)" },
  ]}
/>
```

**Step 6: Commit**

```bash
git add backend/wanted_search.py backend/config.py frontend/src/pages/Settings/
git commit -m "feat(phase-31): auto-sync after download with configurable engine"
```

---

## Phase 32 — Waveform Editor

### Task 32-1: Backend audio extraction

**Files:**
- Modify: `backend/routes/tools.py` (add one endpoint)

**Step 1: Add `/tools/waveform-extract` to `backend/routes/tools.py`**

```python
import hashlib
import tempfile

WAVEFORM_CACHE: dict = {}  # (path, mtime) -> temp_file_path


@bp.route("/waveform-extract", methods=["POST"])
def waveform_extract():
    """Extract audio from video as Opus for waveform display.
    ---
    post:
      summary: Extract audio waveform
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: [video_path]
              properties:
                video_path:
                  type: string
    """
    from flask import send_file
    data = request.get_json(force=True, silent=True) or {}
    video_path = data.get("video_path", "")

    if not video_path:
        return jsonify({"error": "video_path is required"}), 400

    from config import map_path
    video_path = map_path(video_path)

    if not os.path.exists(video_path):
        return jsonify({"error": f"Video not found: {video_path}"}), 404

    mtime = os.path.getmtime(video_path)
    cache_key = (video_path, mtime)

    if cache_key in WAVEFORM_CACHE and os.path.exists(WAVEFORM_CACHE[cache_key]):
        audio_path = WAVEFORM_CACHE[cache_key]
    else:
        # Extract audio as Opus (mono, 22kHz — sufficient for waveform)
        tmp = tempfile.NamedTemporaryFile(suffix=".opus", delete=False)
        tmp.close()
        cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-vn", "-ac", "1", "-ar", "22050",
            "-c:a", "libopus", "-b:a", "32k",
            tmp.name
        ]
        try:
            result = subprocess.run(cmd, capture_output=True, timeout=120)
        except subprocess.TimeoutExpired:
            return jsonify({"error": "Audio extraction timed out"}), 500

        if result.returncode != 0:
            return jsonify({"error": "ffmpeg audio extraction failed"}), 500

        WAVEFORM_CACHE[cache_key] = tmp.name
        audio_path = tmp.name

    # Return URL to audio file — served via a static temp endpoint
    filename = os.path.basename(audio_path)
    return jsonify({
        "audio_url": f"/api/v1/tools/waveform-audio/{filename}",
        "duration_s": _get_duration(video_path),
    })


@bp.route("/waveform-audio/<filename>", methods=["GET"])
def serve_waveform_audio(filename: str):
    """Serve extracted waveform audio file."""
    from flask import send_file
    import tempfile
    tmp_dir = tempfile.gettempdir()
    audio_path = os.path.join(tmp_dir, filename)
    if not os.path.exists(audio_path) or not filename.endswith(".opus"):
        return jsonify({"error": "Not found"}), 404
    return send_file(audio_path, mimetype="audio/ogg")


def _get_duration(video_path: str) -> float:
    """Get video duration in seconds via ffprobe."""
    cmd = ["ffprobe", "-v", "quiet", "-print_format", "json",
           "-show_format", video_path]
    try:
        r = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        import json as _json
        data = _json.loads(r.stdout)
        return float(data.get("format", {}).get("duration", 0))
    except Exception:
        return 0.0
```

**Step 2: Commit backend**

```bash
git add backend/routes/tools.py
git commit -m "feat(phase-32): waveform audio extraction endpoint"
```

---

### Task 32-2: Frontend Waveform tab

**Files:**
- Modify: `frontend/package.json` (add wavesurfer.js)
- Create: `frontend/src/components/editor/WaveformTab.tsx`
- Modify: `frontend/src/components/editor/SubtitleEditorModal.tsx`

**Step 1: Install wavesurfer.js**

```bash
cd frontend && npm install wavesurfer.js @wavesurfer/regions --legacy-peer-deps
```

**Step 2: Create `frontend/src/components/editor/WaveformTab.tsx`**

```tsx
import { useEffect, useRef, useState } from "react";
import WaveSurfer from "wavesurfer.js";
import RegionsPlugin from "@wavesurfer/regions";
import type { SubtitleCue } from "@/types";
import { extractWaveform } from "@/api/client";

interface Props {
  videoPath: string;
  cues: SubtitleCue[];
  onCuesChange: (cues: SubtitleCue[]) => void;
}

export function WaveformTab({ videoPath, cues, onCuesChange }: Props) {
  const containerRef = useRef<HTMLDivElement>(null);
  const wsRef = useRef<WaveSurfer | null>(null);
  const regionsRef = useRef<ReturnType<typeof RegionsPlugin.create> | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    if (!containerRef.current || !videoPath) return;

    const regions = RegionsPlugin.create();
    regionsRef.current = regions;

    const ws = WaveSurfer.create({
      container: containerRef.current,
      waveColor: "#52525b",
      progressColor: "#3b82f6",
      height: 80,
      plugins: [regions],
    });
    wsRef.current = ws;

    extractWaveform(videoPath)
      .then(res => ws.load(res.data.audio_url))
      .catch(() => setError("Waveform konnte nicht geladen werden"))
      .finally(() => setLoading(false));

    ws.on("ready", () => {
      // Add regions for each cue
      cues.forEach(cue => {
        regions.addRegion({
          id: cue.id,
          start: cue.startSeconds,
          end: cue.endSeconds,
          content: cue.text.slice(0, 30),
          color: "rgba(59, 130, 246, 0.2)",
          drag: true,
          resize: true,
        });
      });
    });

    regions.on("region-updated", region => {
      const updated = cues.map(c =>
        c.id === region.id
          ? { ...c, startSeconds: region.start, endSeconds: region.end }
          : c
      );
      onCuesChange(updated);
    });

    return () => ws.destroy();
  }, [videoPath]);

  if (error) return <p className="text-red-400 text-sm p-4">{error}</p>;
  if (loading) return <p className="text-zinc-400 text-sm p-4">Waveform wird geladen…</p>;

  return (
    <div className="p-4">
      <p className="text-xs text-zinc-500 mb-2">
        Cues ziehen zum Verschieben, Ränder zum Anpassen der Timing-Grenzen.
      </p>
      <div ref={containerRef} className="rounded bg-zinc-900 overflow-hidden" />
    </div>
  );
}
```

**Step 3: Add "Waveform" tab to `SubtitleEditorModal.tsx`**

```tsx
import { WaveformTab } from "./WaveformTab";

// In the tab list alongside "Editor":
<button onClick={() => setActiveTab("waveform")}>Waveform</button>

// In tab content:
{activeTab === "waveform" && (
  <WaveformTab
    videoPath={episode.file_path}
    cues={cues}
    onCuesChange={setCues}
  />
)}
```

**Step 4: Add API call to `client.ts`**

```typescript
export const extractWaveform = (videoPath: string) =>
  apiClient.post<{ audio_url: string; duration_s: number }>(
    "/tools/waveform-extract",
    { video_path: videoPath }
  );
```

**Step 5: Commit**

```bash
git add frontend/src/components/editor/WaveformTab.tsx \
        frontend/src/components/editor/SubtitleEditorModal.tsx \
        frontend/src/api/client.ts frontend/package.json
git commit -m "feat(phase-32): waveform editor tab with wavesurfer.js and draggable cue regions"
```

---

## Phase 33 — Format Conversion

### Task 33-1: Backend convert endpoint

**Files:**
- Modify: `backend/routes/tools.py`

**Step 1: Add `/tools/convert` to `backend/routes/tools.py`**

```python
SUPPORTED_FORMATS = {"srt", "ass", "ssa", "vtt"}
PYSUBS2_EXT = {"srt": "srt", "ass": "ass", "ssa": "ssa", "vtt": "vtt"}


@bp.route("/convert", methods=["POST"])
def convert_format():
    """Convert subtitle format via pysubs2.
    ---
    post:
      summary: Convert subtitle format
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                file_path:
                  type: string
                track_index:
                  type: integer
                video_path:
                  type: string
                target_format:
                  type: string
                  enum: [srt, ass, ssa, vtt]
    """
    import pysubs2
    from config import map_path

    data = request.get_json(force=True, silent=True) or {}
    target_format = data.get("target_format", "").lower()
    file_path = data.get("file_path", "")
    track_index = data.get("track_index")
    video_path = data.get("video_path", "")

    if target_format not in SUPPORTED_FORMATS:
        return jsonify({"error": f"target_format must be one of {sorted(SUPPORTED_FORMATS)}"}), 400

    # Source: either existing file or embedded track
    if track_index is not None:
        if not video_path:
            return jsonify({"error": "video_path required when track_index is set"}), 400
        video_path = map_path(video_path)
        if not os.path.exists(video_path):
            return jsonify({"error": f"Video not found: {video_path}"}), 404

        import tempfile
        from ass_utils import get_media_streams, extract_subtitle_stream
        probe = get_media_streams(video_path)
        stream = next(
            (s for s in probe.get("streams", []) if s.get("index") == track_index),
            None,
        )
        if not stream:
            return jsonify({"error": f"Track {track_index} not found"}), 404
        codec = stream.get("codec_name", "subrip")
        ext = "ass" if codec in ("ass", "ssa") else "srt"
        tmp = tempfile.NamedTemporaryFile(suffix=f".{ext}", delete=False)
        tmp.close()
        extract_subtitle_stream(video_path, {"sub_index": track_index, "format": codec}, tmp.name)
        source_path = tmp.name
        cleanup_source = True
        base_output = os.path.splitext(video_path)[0]
    else:
        if not file_path:
            return jsonify({"error": "file_path or track_index required"}), 400
        source_path = map_path(file_path)
        if not os.path.exists(source_path):
            return jsonify({"error": f"File not found: {source_path}"}), 404
        cleanup_source = False
        base_output = os.path.splitext(source_path)[0]

    output_path = f"{base_output}.converted.{PYSUBS2_EXT[target_format]}"

    try:
        subs = pysubs2.load(source_path)
        subs.save(output_path, format_=target_format)
    except Exception as e:
        return jsonify({"error": f"Conversion failed: {e}"}), 500
    finally:
        if cleanup_source:
            try:
                os.unlink(source_path)
            except OSError:
                pass

    logger.info("Converted %s → %s (%s)", source_path, output_path, target_format)
    return jsonify({"output_path": output_path, "format": target_format})
```

**Step 2: Write tests**

```python
# backend/tests/test_convert.py
def test_convert_srt_to_ass(client, tmp_path):
    srt = tmp_path / "ep.de.srt"
    srt.write_text("1\n00:00:01,000 --> 00:00:02,000\nHello\n\n")
    r = client.post("/api/v1/tools/convert",
                    json={"file_path": str(srt), "target_format": "ass"})
    assert r.status_code == 200
    assert r.get_json()["format"] == "ass"
    assert (tmp_path / "ep.de.converted.ass").exists()


def test_convert_invalid_format(client, tmp_path):
    srt = tmp_path / "ep.srt"
    srt.write_text("")
    r = client.post("/api/v1/tools/convert",
                    json={"file_path": str(srt), "target_format": "xyz"})
    assert r.status_code == 400
```

**Step 3: Run and commit**

```bash
cd backend && python -m pytest tests/test_convert.py -v
git add backend/routes/tools.py backend/tests/test_convert.py
git commit -m "feat(phase-33): format conversion endpoint — ASS/SRT/SSA/VTT via pysubs2"
```

---

### Task 33-2: Frontend convert button

**Files:**
- Modify: `frontend/src/components/tracks/TrackPanel.tsx`
- Modify: `frontend/src/api/client.ts`

**Step 1: Add API call to `client.ts`**

```typescript
export const convertSubtitle = (params: {
  file_path?: string;
  track_index?: number;
  video_path?: string;
  target_format: "srt" | "ass" | "ssa" | "vtt";
}) => apiClient.post<{ output_path: string; format: string }>("/tools/convert", params);
```

**Step 2: Add convert button in `TrackPanel.tsx`**

For each subtitle track, add alongside Extrahieren/Als Quelle:
```tsx
<select
  className="text-xs bg-zinc-800 border border-zinc-700 rounded px-1"
  defaultValue=""
  onChange={async e => {
    if (!e.target.value) return;
    await convertSubtitle({
      track_index: t.index,
      video_path: videoPath,
      target_format: e.target.value as any,
    });
    e.target.value = "";
  }}
>
  <option value="">Konvertieren…</option>
  {["srt", "ass", "vtt"].filter(f => f !== t.codec.replace("subrip","srt")).map(f => (
    <option key={f} value={f}>{f.toUpperCase()}</option>
  ))}
</select>
```

**Step 3: Commit**

```bash
git add frontend/src/components/tracks/TrackPanel.tsx frontend/src/api/client.ts
git commit -m "feat(phase-33): format conversion UI in TrackPanel"
```

---

## Phase 34 — OCR Pipeline (Improved)

### Task 34-1: Batch OCR endpoint

**Files:**
- Modify: `backend/routes/ocr.py`
- Modify: `backend/services/ocr_extractor.py`

**Step 1: Add batch extraction to `backend/services/ocr_extractor.py`**

```python
def batch_ocr_track(video_path: str, stream_index: int,
                    language: str = "eng") -> list[dict]:
    """Extract and OCR an entire subtitle track from an MKV in one pass.

    Args:
        video_path: Path to the video file
        stream_index: Subtitle stream index (from ffprobe)
        language: Tesseract language code (eng, deu, jpn)

    Returns:
        List of dicts: [{start_ms, end_ms, text}, ...]
    """
    if not TESSERACT_AVAILABLE:
        raise RuntimeError("pytesseract is not available")

    import tempfile
    import glob as _glob
    from concurrent.futures import ThreadPoolExecutor as TPE

    with tempfile.TemporaryDirectory() as tmp_dir:
        # Extract subtitle images — ffmpeg outputs frame%04d.png
        out_pattern = os.path.join(tmp_dir, "frame%08d.png")
        cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-map", f"0:{stream_index}",
            "-vsync", "vfr",
            out_pattern
        ]
        r = subprocess.run(cmd, capture_output=True, timeout=300)
        if r.returncode != 0:
            raise RuntimeError(f"ffmpeg subtitle extraction failed: {r.stderr.decode()[:500]}")

        frames = sorted(_glob.glob(os.path.join(tmp_dir, "frame*.png")))
        if not frames:
            return []

        # OCR frames in parallel
        def _ocr_frame(frame_path: str) -> str:
            img = Image.open(frame_path).convert("L")  # grayscale
            return pytesseract.image_to_string(img, lang=language).strip()

        with TPE(max_workers=4) as pool:
            texts = list(pool.map(_ocr_frame, frames))

    # Deduplicate consecutive identical lines and build cue list
    cues = []
    prev = None
    for text in texts:
        if text and text != prev:
            cues.append({"text": text})
        prev = text

    return cues
```

**Step 2: Add `/ocr/batch-extract` to `backend/routes/ocr.py`**

```python
import uuid, threading
from concurrent.futures import ThreadPoolExecutor as TPE

_ocr_executor = TPE(max_workers=1, thread_name_prefix="batch-ocr")
_ocr_jobs: dict = {}
_ocr_lock = threading.Lock()


@bp.route("/ocr/batch-extract", methods=["POST"])
def batch_extract():
    """Batch OCR an entire PGS/VobSub track from an MKV."""
    data = request.get_json(force=True, silent=True) or {}
    video_path = data.get("video_path", "")
    stream_index = data.get("stream_index")
    language = data.get("language", "eng")

    if not video_path or stream_index is None:
        return jsonify({"error": "video_path and stream_index are required"}), 400

    from config import map_path
    video_path = map_path(video_path)
    if not os.path.exists(video_path):
        return jsonify({"error": f"Video not found: {video_path}"}), 404

    job_id = str(uuid.uuid4())
    with _ocr_lock:
        _ocr_jobs[job_id] = {"status": "queued"}

    def _run(jid, vp, si, lang):
        with _ocr_lock:
            _ocr_jobs[jid]["status"] = "running"
        try:
            from services.ocr_extractor import batch_ocr_track
            cues = batch_ocr_track(vp, si, lang)
            with _ocr_lock:
                _ocr_jobs[jid] = {"status": "completed", "cues": cues}
        except Exception as e:
            with _ocr_lock:
                _ocr_jobs[jid] = {"status": "failed", "error": str(e)}

    _ocr_executor.submit(_run, job_id, video_path, stream_index, language)
    return jsonify({"job_id": job_id}), 202


@bp.route("/ocr/batch-extract/<job_id>", methods=["GET"])
def batch_extract_status(job_id: str):
    with _ocr_lock:
        job = _ocr_jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404
    return jsonify({"job_id": job_id, **job})
```

**Step 3: Commit**

```bash
git add backend/routes/ocr.py backend/services/ocr_extractor.py
git commit -m "feat(phase-34): batch OCR pipeline for PGS/VobSub tracks"
```

---

## Phase 35 — Quality Fixes

### Task 35-1: Overlap Fix, Timing Normalization, Merge/Split, Spell-Check

**Files:**
- Modify: `backend/routes/tools.py`
- Modify: `backend/requirements.txt`

**Step 1: Add `pyhunspell` to `backend/requirements.txt`**

```
pyhunspell>=0.5.5
```

Note: pyhunspell requires hunspell dev headers. In Dockerfile, add before pip install:
```dockerfile
RUN apt-get install -y --no-install-recommends libhunspell-dev
```

**Step 2: Add all five fix endpoints to `backend/routes/tools.py`**

```python
# ── Overlap Fix ────────────────────────────────────────────────────────────────

@bp.route("/overlap-fix", methods=["POST"])
def overlap_fix():
    """Trim overlapping cue end times."""
    import pysubs2
    data = request.get_json(force=True, silent=True) or {}
    err, abs_path = _validate_file_path(data.get("file_path", ""))
    if err:
        return jsonify({"error": err}), 400

    bak = _create_backup(abs_path)
    subs = pysubs2.load(abs_path)
    fixed = 0
    for i in range(len(subs) - 1):
        if subs[i].end > subs[i + 1].start:
            subs[i].end = subs[i + 1].start - 1
            fixed += 1
    subs.save(abs_path)
    logger.info("overlap-fix: %d overlaps fixed in %s", fixed, abs_path)
    return jsonify({"fixed": fixed, "backup_path": bak})


# ── Timing Normalization ────────────────────────────────────────────────────────

@bp.route("/timing-normalize", methods=["POST"])
def timing_normalize():
    """Extend too-short cues, flag too-long cues."""
    import pysubs2
    data = request.get_json(force=True, silent=True) or {}
    err, abs_path = _validate_file_path(data.get("file_path", ""))
    if err:
        return jsonify({"error": err}), 400
    min_ms = int(data.get("min_ms", 500))
    max_ms = int(data.get("max_ms", 10000))

    bak = _create_backup(abs_path)
    subs = pysubs2.load(abs_path)
    extended = split_long = 0
    for cue in subs:
        dur = cue.end - cue.start
        if dur < min_ms:
            cue.end = cue.start + min_ms
            extended += 1
        # Long cues: just report — splitting requires inserting new cues (out of scope for single pass)
        elif dur > max_ms:
            split_long += 1
    subs.save(abs_path)
    return jsonify({"extended": extended, "too_long": split_long, "backup_path": bak})


# ── Merge Lines ─────────────────────────────────────────────────────────────────

@bp.route("/merge-lines", methods=["POST"])
def merge_lines():
    """Merge consecutive cues with a short gap between them."""
    import pysubs2
    data = request.get_json(force=True, silent=True) or {}
    err, abs_path = _validate_file_path(data.get("file_path", ""))
    if err:
        return jsonify({"error": err}), 400
    gap_ms = int(data.get("gap_ms", 200))

    bak = _create_backup(abs_path)
    subs = pysubs2.load(abs_path)
    merged = 0
    i = 0
    new_subs = pysubs2.SSAFile()
    while i < len(subs):
        cue = subs[i]
        while (i + 1 < len(subs) and
               subs[i + 1].start - cue.end <= gap_ms):
            cue = pysubs2.SSAEvent(
                start=cue.start,
                end=subs[i + 1].end,
                text=cue.text + "\\N" + subs[i + 1].text,
            )
            i += 1
            merged += 1
        new_subs.append(cue)
        i += 1
    new_subs.save(abs_path)
    return jsonify({"merged": merged, "backup_path": bak})


# ── Split Lines ─────────────────────────────────────────────────────────────────

@bp.route("/split-lines", methods=["POST"])
def split_lines():
    """Split cues with \\N or long lines at natural boundaries."""
    import pysubs2
    data = request.get_json(force=True, silent=True) or {}
    err, abs_path = _validate_file_path(data.get("file_path", ""))
    if err:
        return jsonify({"error": err}), 400
    max_chars = int(data.get("max_chars", 80))

    bak = _create_backup(abs_path)
    subs = pysubs2.load(abs_path)
    new_subs = pysubs2.SSAFile()
    split_count = 0

    for cue in subs:
        parts = cue.text.split("\\N")
        if len(parts) <= 1 and len(cue.text) <= max_chars:
            new_subs.append(cue)
            continue
        dur = cue.end - cue.start
        per_part = dur // max(len(parts), 1)
        for idx, part in enumerate(parts):
            new_subs.append(pysubs2.SSAEvent(
                start=cue.start + idx * per_part,
                end=cue.start + (idx + 1) * per_part,
                text=part.strip(),
            ))
        split_count += 1

    new_subs.save(abs_path)
    return jsonify({"split": split_count, "backup_path": bak})


# ── Spell Check ─────────────────────────────────────────────────────────────────

@bp.route("/spell-check", methods=["POST"])
def spell_check():
    """Spell-check subtitle file using hunspell. Returns list of misspelled words."""
    import pysubs2
    import re
    data = request.get_json(force=True, silent=True) or {}
    err, abs_path = _validate_file_path(data.get("file_path", ""))
    if err:
        return jsonify({"error": err}), 400
    language = data.get("language", "de_DE")  # hunspell dict name

    try:
        import hunspell
        hobj = hunspell.HunSpell(
            f"/usr/share/hunspell/{language}.dic",
            f"/usr/share/hunspell/{language}.aff",
        )
    except Exception as e:
        return jsonify({"error": f"Hunspell not available for {language}: {e}"}), 503

    subs = pysubs2.load(abs_path)
    errors = []
    word_re = re.compile(r"\b[a-zA-ZäöüÄÖÜß]+\b")
    for cue in subs:
        clean = re.sub(r"\{[^}]+\}", "", cue.text)  # strip ASS tags
        for word in word_re.findall(clean):
            if not hobj.spell(word):
                errors.append({"word": word, "start_ms": cue.start, "text": cue.text})

    return jsonify({"errors": errors, "total": len(errors)})
```

**Step 3: Write tests for overlap-fix and merge-lines**

```python
# backend/tests/test_quality_fixes.py
import pysubs2, pytest

def _make_srt(tmp_path, content):
    p = tmp_path / "test.srt"
    p.write_text(content)
    return str(p)


def test_overlap_fix(client, tmp_path):
    srt_content = (
        "1\n00:00:01,000 --> 00:00:03,000\nHello\n\n"
        "2\n00:00:02,000 --> 00:00:04,000\nWorld\n\n"
    )
    path = _make_srt(tmp_path, srt_content)
    r = client.post("/api/v1/tools/overlap-fix", json={"file_path": path})
    assert r.status_code == 200
    assert r.get_json()["fixed"] == 1
    subs = pysubs2.load(path)
    assert subs[0].end <= subs[1].start


def test_timing_normalize_extends_short_cue(client, tmp_path):
    srt_content = "1\n00:00:01,000 --> 00:00:01,100\nHi\n\n"
    path = _make_srt(tmp_path, srt_content)
    r = client.post("/api/v1/tools/timing-normalize",
                    json={"file_path": path, "min_ms": 500})
    assert r.status_code == 200
    assert r.get_json()["extended"] == 1
    subs = pysubs2.load(path)
    assert subs[0].end - subs[0].start >= 500


def test_merge_lines(client, tmp_path):
    srt_content = (
        "1\n00:00:01,000 --> 00:00:01,500\nA\n\n"
        "2\n00:00:01,600 --> 00:00:02,000\nB\n\n"
    )
    path = _make_srt(tmp_path, srt_content)
    r = client.post("/api/v1/tools/merge-lines", json={"file_path": path, "gap_ms": 200})
    assert r.status_code == 200
    assert r.get_json()["merged"] == 1
```

**Step 4: Run tests**

```bash
cd backend && python -m pytest tests/test_quality_fixes.py -v
```

**Step 5: Commit backend**

```bash
git add backend/routes/tools.py backend/requirements.txt backend/tests/test_quality_fixes.py
git commit -m "feat(phase-35): quality fixes — overlap, timing, merge, split, spell-check"
```

---

### Task 35-2: Quality Fixes Frontend buttons

**Files:**
- Modify: `frontend/src/api/client.ts`
- Modify: `frontend/src/components/editor/SubtitleEditorModal.tsx`

**Step 1: Add API calls to `client.ts`**

```typescript
const toolPost = (endpoint: string, params: object) =>
  apiClient.post(`/tools/${endpoint}`, params);

export const overlapFix = (filePath: string) => toolPost("overlap-fix", { file_path: filePath });
export const timingNormalize = (filePath: string, minMs = 500, maxMs = 10000) =>
  toolPost("timing-normalize", { file_path: filePath, min_ms: minMs, max_ms: maxMs });
export const mergeLines = (filePath: string, gapMs = 200) =>
  toolPost("merge-lines", { file_path: filePath, gap_ms: gapMs });
export const splitLines = (filePath: string, maxChars = 80) =>
  toolPost("split-lines", { file_path: filePath, max_chars: maxChars });
export const spellCheck = (filePath: string, language = "de_DE") =>
  toolPost("spell-check", { file_path: filePath, language });
```

**Step 2: Add toolbar buttons in `SubtitleEditorModal.tsx`**

```tsx
// In the editor toolbar:
<div className="flex gap-1 flex-wrap">
  <ToolButton label="Überlappungen" onClick={() => overlapFix(filePath)} />
  <ToolButton label="Timing" onClick={() => timingNormalize(filePath)} />
  <ToolButton label="Zusammenführen" onClick={() => mergeLines(filePath)} />
  <ToolButton label="Aufteilen" onClick={() => splitLines(filePath)} />
  <ToolButton label="Rechtschreibung" onClick={() => spellCheck(filePath)} />
</div>
```

**Step 3: Commit**

```bash
git add frontend/src/components/editor/SubtitleEditorModal.tsx frontend/src/api/client.ts
git commit -m "feat(phase-35): quality fix buttons in subtitle editor toolbar"
```

---

## Final: Version bump and build

```bash
# 1. Update version
echo "0.11.0-beta" > backend/VERSION
git add backend/VERSION
git commit -m "chore: bump version to 0.11.0-beta"

# 2. Build and deploy
docker build -t ghcr.io/abrechen2/sublarr:0.11.0-beta .
docker save ghcr.io/abrechen2/sublarr:0.11.0-beta | ssh root@192.168.178.36 docker load
ssh root@192.168.178.36 "cd /mnt/user/Unraid/CC/Sublarr && \
  VERSION=0.11.0-beta docker compose -f docker-compose.yml -f docker-compose.cardinal.yml up -d"
ssh root@192.168.178.36 "curl -s http://localhost:5765/api/v1/health"
```
