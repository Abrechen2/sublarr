# Reliability Baseline â€” Stand 2026-02-XX

> **Zweck:** Dokumentation des aktuellen ZuverlÃ¤ssigkeits-Status als Ausgangspunkt fÃ¼r StabilisierungsmaÃŸnahmen.
> Diese Baseline wird wÃ¶chentlich aktualisiert, um Fortschritt zu messen.

## Executive Summary

**Status:** âš ï¸ **Stabilisierungsbedarf erkannt**

- **CI-Pipeline:** 15+ Checks mit `continue-on-error: true` â€” Fehler werden ignoriert
- **Test-Suite:** Struktur vorhanden, aber Flaky-Tests nicht isoliert
- **Error-Handling:** Strukturiertes System vorhanden, aber nicht alle kritischen Pfade abgedeckt
- **Health-Checks:** Basis vorhanden, aber nicht alle Ausfallursachen Ã¼berwacht

---

## 1. CI-Pipeline Status

### Fail-Open Checks (kritisch)

Die folgenden Checks schlagen nicht fehl, auch wenn sie Fehler finden:

| Check | Job | Status | PrioritÃ¤t |
|-------|-----|--------|-----------|
| `mypy` (Type Checking) | `backend` | `continue-on-error: true` | ğŸ”´ **Hoch** |
| Coverage Upload | `backend`, `frontend` | `fail_ci_if_error: false` | ğŸŸ¡ Mittel |
| Code Quality (vulture, bandit, radon) | `code-quality` | `continue-on-error: true` | ğŸŸ¡ Mittel |
| Security Scans (pip-audit, npm audit, trivy) | `security-scan` | `continue-on-error: true` | ğŸ”´ **Hoch** |
| License Checks | `license-check` | `continue-on-error: true` | ğŸŸ¢ Niedrig |
| E2E Tests | `e2e-tests` | `continue-on-error: true` | ğŸ”´ **Hoch** |
| Performance Tests | `performance-tests` | `continue-on-error: true` | ğŸŸ¢ Niedrig |

**Gesamt:** 15+ Checks, die Fehler verstecken kÃ¶nnen.

### Verbindliche Checks (funktionieren)

- âœ… `ruff check` (Linting)
- âœ… `ruff format --check` (Formatting)
- âœ… `pytest` (Backend Tests)
- âœ… `vitest` (Frontend Tests)
- âœ… `eslint` (Frontend Linting)
- âœ… `prettier --check` (Frontend Formatting)
- âœ… `tsc --noEmit` (TypeScript Type Check)
- âœ… Integration Tests

**Problem:** `ci-status` Job prÃ¼ft nur `backend` und `frontend` Jobs â€” andere Fehler werden ignoriert.

---

## 2. Kritische User-Flows

### Flow 1: Subtitle-Suche und Download (Kern-Workflow)

**Pfad:**
1. Wanted-Scanner erkennt fehlende Untertitel
2. Provider-Suche (AnimeTosho, Jimaku, OpenSubtitles, SubDL)
3. Beste Subtitle auswÃ¤hlen (Scoring)
4. Download + Extraktion (ZIP/RAR/XZ)
5. Optional: Ãœbersetzung via LLM (Ollama/DeepL/etc.)
6. Datei speichern + Jellyfin/Emby/Plex Refresh

**Risikopunkte:**
- Provider-API-Fehler (Rate Limits, Timeouts)
- Datei-Extraktion (ZIP/RAR/XZ kann fehlschlagen)
- Ãœbersetzungs-Pipeline (Ollama-Verbindung, Model-Fehler)
- Dateisystem-Operationen (Berechtigungen, Speicherplatz)

**Smoke-Test:**
```bash
# API-Endpoint testen
curl http://localhost:5765/api/v1/wanted/refresh
curl http://localhost:5765/api/v1/wanted/<id>/search
```

### Flow 2: Ãœbersetzung (ASS/SRT)

**Pfad:**
1. Embedded Subtitle Detection (ffprobe)
2. ASS-Parsing (Styles, Events)
3. Style-Klassifizierung (Dialog vs. Signs/Songs)
4. LLM-Ãœbersetzung (Batch-Processing)
5. Re-Assembly (Tags, Formatting)
6. Validierung (Zeilenanzahl, Halluzination)

**Risikopunkte:**
- ffprobe nicht verfÃ¼gbar oder fehlerhaft
- ASS-Parsing-Fehler (ungÃ¼ltige Dateien)
- LLM-Verbindung (Ollama nicht erreichbar)
- ÃœbersetzungsqualitÃ¤t (Halluzinationen, falsche Sprachen)

**Smoke-Test:**
```bash
# Health-Check
curl http://localhost:5765/api/v1/health/detailed
# Sollte "ollama" oder Translation-Backend-Status enthalten
```

### Flow 3: Webhook-Automatisierung

**Pfad:**
1. Sonarr/Radarr sendet Webhook (Download Complete)
2. Sublarr empfÃ¤ngt Webhook
3. Auto-Scan â†’ Auto-Search â†’ Auto-Translate
4. Notification (Apprise)

**Risikopunkte:**
- Webhook-Empfang (Auth, Parsing)
- Race Conditions (mehrere Webhooks gleichzeitig)
- Sonarr/Radarr nicht erreichbar

**Smoke-Test:**
```bash
# Webhook simulieren
curl -X POST http://localhost:5765/api/v1/webhook/sonarr \
  -H "Content-Type: application/json" \
  -d '{"eventType": "Download"}'
```

### Flow 4: Frontend â†’ Backend API

**Pfad:**
1. React-App lÃ¤dt
2. API-Calls (Library, Wanted, Settings)
3. WebSocket-Verbindung (Real-Time Updates)
4. UI-Updates

**Risikopunkte:**
- API-Auth (API-Key)
- CORS-Probleme
- WebSocket-Verbindung bricht ab
- Frontend-Build-Fehler

**Smoke-Test:**
```bash
# Frontend baut?
cd frontend && npm run build
# API erreichbar?
curl http://localhost:5765/api/v1/health
```

---

## 3. Bekannte Probleme / Fehlerbilder

### Problem 1: mypy Type-Errors werden ignoriert

**Symptom:** CI lÃ¤uft grÃ¼n, aber Type-Errors existieren.

**Impact:** ğŸŸ¡ Mittel â€” Kann zu Runtime-Fehlern fÃ¼hren.

**LÃ¶sung:** mypy schrittweise verbindlich machen (siehe Woche 3).

### Problem 2: Security-Scans werden ignoriert

**Symptom:** `pip-audit`, `npm audit`, `trivy` finden Vulnerabilities, aber CI schlÃ¤gt nicht fehl.

**Impact:** ğŸ”´ **Hoch** â€” Security-Risiken werden nicht erkannt.

**LÃ¶sung:** Security-Scans verbindlich machen, aber nur fÃ¼r kritische Vulnerabilities.

### Problem 3: E2E-Tests sind optional

**Symptom:** Playwright-Tests schlagen fehl, aber CI lÃ¤uft weiter.

**Impact:** ğŸ”´ **Hoch** â€” Frontend-Integration wird nicht getestet.

**LÃ¶sung:** E2E-Tests stabilisieren oder in separaten Job isolieren.

### Problem 4: Provider-Fehler werden nicht ausreichend abgefangen

**Symptom:** Provider-API-Fehler fÃ¼hren zu unhandled Exceptions.

**Impact:** ğŸ”´ **Hoch** â€” Kern-Workflow bricht ab.

**LÃ¶sung:** Defensive Guards in `wanted_search.py` und Provider-Code.

### Problem 5: Ãœbersetzungs-Pipeline hat keine Fallback-Mechanismen

**Symptom:** Wenn Ollama nicht erreichbar ist, bricht alles ab.

**Impact:** ğŸŸ¡ Mittel â€” Fallback-Chains existieren, aber nicht Ã¼berall.

**LÃ¶sung:** Fallback-Chains Ã¼berall implementieren (siehe Woche 2).

---

## 4. Test-Suite Status

### Backend Tests

**Struktur:**
- Unit Tests: `backend/tests/test_*.py`
- Integration Tests: `backend/tests/integration/`
- Performance Tests: `backend/tests/performance/`

**Coverage-Ziel:** 80%+ (laut `pytest.ini`)

**Bekannte Flaky-Tests:** (noch zu identifizieren)

### Frontend Tests

**Struktur:**
- Unit Tests: `frontend/src/**/*.test.tsx`
- E2E Tests: `frontend/tests/e2e/` (Playwright)

**Coverage-Ziel:** 70%+ (laut `vitest.config.ts`)

**Bekannte Flaky-Tests:** E2E-Tests (werden ignoriert)

---

## 5. Error-Handling Status

### Strukturiertes Error-System vorhanden

**Datei:** `backend/error_handler.py`

**Features:**
- âœ… Exception-Hierarchie (`SublarrError`, `TranslationError`, `DatabaseError`, etc.)
- âœ… Strukturierte JSON-Responses
- âœ… Request-ID-Tracking
- âœ… Troubleshooting-Hints

**Fehlend:**
- âŒ Nicht alle kritischen Pfade nutzen strukturierte Errors
- âŒ Provider-Fehler werden nicht immer abgefangen
- âŒ Dateisystem-Operationen haben keine Guards

---

## 6. Health-Checks Status

### Basis vorhanden

**Endpoints:**
- `/api/v1/health` â€” Basis-Health-Check
- `/api/v1/health/detailed` â€” Detaillierter Status

**Ãœberwachte Komponenten:**
- âœ… Database-Connectivity
- âœ… Provider-Health (teilweise)
- âœ… Translation-Backend-Status (teilweise)
- âœ… Media-Server-Status (teilweise)

**Fehlend:**
- âŒ Disk-Space-Checks
- âŒ Memory/CPU-Monitoring
- âŒ Provider-Response-Time-Tracking (nur teilweise)
- âŒ Ãœbersetzungs-Quality-Metrics

---

## 7. Smoke-Tests (Kern-Workflows)

### Definition

Smoke-Tests sind minimale Tests, die prÃ¼fen, ob die Kern-FunktionalitÃ¤t funktioniert.

### Test 1: API ist erreichbar

```bash
curl http://localhost:5765/api/v1/health
# Erwartet: {"status": "ok"} oder Ã¤hnlich
```

### Test 2: Frontend baut

```bash
cd frontend && npm run build
# Erwartet: Build erfolgreich, keine Fehler
```

### Test 3: Backend-Tests laufen

```bash
cd backend && pytest tests/test_server.py -v
# Erwartet: Alle Tests grÃ¼n
```

### Test 4: Provider-System funktioniert

```bash
curl http://localhost:5765/api/v1/providers
# Erwartet: Liste von Providern
```

### Test 5: Ãœbersetzungs-Backend ist erreichbar

```bash
curl http://localhost:5765/api/v1/health/detailed
# Erwartet: Translation-Backend-Status
```

---

## 8. Metriken (Vorher/Nachher)

### Baseline (Stand: 2026-02-XX)

| Metrik | Wert | Ziel |
|--------|------|------|
| CI-Checks mit `continue-on-error` | 15+ | 0 (kritische Checks) |
| Flaky-Tests | ? | 0 |
| Test-Coverage (Backend) | ? | 80%+ |
| Test-Coverage (Frontend) | ? | 70%+ |
| Bekannte kritische Bugs | ? | 0 |
| Smoke-Tests definiert | 5 | 5+ |

### Nach 30 Tagen (Ziel)

| Metrik | Ziel |
|--------|------|
| CI-Checks mit `continue-on-error` | â‰¤ 5 (nur optionale Checks) |
| Flaky-Tests | 0 |
| Test-Coverage (Backend) | 80%+ |
| Test-Coverage (Frontend) | 70%+ |
| Bekannte kritische Bugs | 0 |
| Smoke-Tests definiert | 10+ |

---

## 9. PrioritÃ¤ten (Top-3 fÃ¼r Woche 2)

1. **Provider-Fehler abfangen** â€” Defensive Guards in `wanted_search.py`
2. **Ãœbersetzungs-Pipeline absichern** â€” Fallback-Mechanismen
3. **Dateisystem-Operationen absichern** â€” Guards fÃ¼r Speicherplatz, Berechtigungen

---

## 10. NÃ¤chste Schritte

- [ ] Woche 1: Baseline dokumentiert âœ…
- [ ] Woche 2: Top-3 Reliability-Bugs beheben
- [ ] Woche 3: CI-Gates verschÃ¤rfen
- [ ] Woche 4: Runbook + Monitoring

---

## 11. Fortschritt (Woche 1-4)

### Woche 1 âœ… (abgeschlossen)
- [x] Reliability-Baseline dokumentiert
- [x] Smoke-Tests erstellt (Bash + PowerShell)
- [x] Kritische User-Flows identifiziert

### Woche 2 âœ… (abgeschlossen)
- [x] Provider-Fehler abgefangen (defensive Guards in `wanted_search.py`)
- [x] Dateisystem-Operationen abgesichert (Disk-Space-Check in `save_subtitle`)
- [x] Ãœbersetzungs-Pipeline verbessert (bessere Fehlerbehandlung, Cleanup)
- [x] Regressionstests erstellt (`test_wanted_search_reliability.py`)

### Woche 3 âœ… (abgeschlossen)
- [x] mypy Type-Checking verbindlich gemacht
- [x] Security-Scans verschÃ¤rft (fail on high/critical)
- [x] CI-Status-Job verbessert (kritische vs. optionale Jobs)

### Woche 4 âœ… (abgeschlossen)
- [x] Incident-Runbook erstellt (`INCIDENT_RUNBOOK.md`)
- [x] Health-Checks bereits vorhanden (`/api/v1/health/detailed`)

---

**Letzte Aktualisierung:** 2026-02-XX  
**NÃ¤chste Review:** WÃ¶chentlich (jeden Montag)
