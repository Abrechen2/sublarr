"""RQ (Redis Queue) job queue implementation.

Uses RQ with Redis for persistent job queues that survive container restarts.
Requires a separate `rq worker` process to execute enqueued jobs.
"""

import contextlib
import logging
from datetime import datetime

from job_queue import JobInfo, JobStatus, QueueBackend

logger = logging.getLogger(__name__)

# Map RQ job statuses to our unified JobStatus enum
_RQ_STATUS_MAP = {
    "queued": JobStatus.QUEUED,
    "started": JobStatus.RUNNING,
    "finished": JobStatus.COMPLETED,
    "failed": JobStatus.FAILED,
    "stopped": JobStatus.CANCELLED,
    "canceled": JobStatus.CANCELLED,
    "cancelled": JobStatus.CANCELLED,
    "deferred": JobStatus.QUEUED,
    "scheduled": JobStatus.QUEUED,
}


def _rq_job_to_info(job) -> JobInfo:
    """Convert an RQ Job object to our JobInfo dataclass.

    Args:
        job: An rq.job.Job instance.

    Returns:
        JobInfo with all available fields populated.
    """
    status = _RQ_STATUS_MAP.get(job.get_status(), JobStatus.QUEUED)

    # Extract timestamps, converting datetime to ISO string
    enqueued_at = ""
    if job.enqueued_at:
        enqueued_at = (
            job.enqueued_at.isoformat()
            if isinstance(job.enqueued_at, datetime)
            else str(job.enqueued_at)
        )

    started_at = None
    if job.started_at:
        started_at = (
            job.started_at.isoformat()
            if isinstance(job.started_at, datetime)
            else str(job.started_at)
        )

    completed_at = None
    if job.ended_at:
        completed_at = (
            job.ended_at.isoformat() if isinstance(job.ended_at, datetime) else str(job.ended_at)
        )

    # Get function name
    func_name = job.func_name or ""

    # Get result/error
    result = None
    error = None
    if status == JobStatus.COMPLETED:
        with contextlib.suppress(Exception):
            result = job.result
    elif status == JobStatus.FAILED:
        error = str(job.exc_info) if job.exc_info else "Unknown error"

    return JobInfo(
        id=job.id,
        func_name=func_name,
        status=status,
        enqueued_at=enqueued_at,
        started_at=started_at,
        completed_at=completed_at,
        result=result,
        error=error,
    )


class RQJobQueue(QueueBackend):
    """QueueBackend implementation using RQ (Redis Queue).

    IMPORTANT: RQ requires a separate worker process to execute jobs.
    This class only ENQUEUES jobs; a separate `rq worker sublarr` process
    must be running to EXECUTE them. For Docker, this means running both
    Flask and an RQ worker (handled by Plan 05 app factory integration).

    Jobs persist in Redis and survive container restarts.
    """

    def __init__(self, redis_client, queue_name: str = "sublarr"):
        """Initialize with an already-connected Redis client.

        Args:
            redis_client: A redis.Redis instance.
            queue_name: Name of the RQ queue (default: "sublarr").
        """
        from rq import Queue

        self.redis_client = redis_client
        self.queue_name = queue_name
        self.queue = Queue(queue_name, connection=redis_client)

    def enqueue(self, func, *args, job_id: str = None, **kwargs) -> str:
        """Enqueue a function for execution by an RQ worker.

        Args:
            func: The callable to execute (must be importable by the worker).
            *args: Positional arguments for the callable.
            job_id: Optional custom job ID. Auto-generated by RQ if not provided.
            **kwargs: Keyword arguments for the callable.

        Returns:
            The RQ job ID.
        """
        enqueue_kwargs = {}
        if job_id is not None:
            enqueue_kwargs["job_id"] = job_id

        job = self.queue.enqueue(func, *args, **kwargs, **enqueue_kwargs)
        logger.debug("Enqueued job %s: %s", job.id, getattr(func, "__name__", str(func)))
        return job.id

    def get_job(self, job_id: str) -> JobInfo | None:
        """Get job status from RQ.

        Args:
            job_id: The job ID to look up.

        Returns:
            JobInfo if found, None if job doesn't exist.
        """
        from rq.exceptions import NoSuchJobError
        from rq.job import Job as RQJob

        try:
            job = RQJob.fetch(job_id, connection=self.redis_client)
            return _rq_job_to_info(job)
        except NoSuchJobError:
            return None
        except Exception as e:
            logger.debug("Error fetching job %s: %s", job_id, e)
            return None

    def cancel_job(self, job_id: str) -> bool:
        """Cancel a pending RQ job.

        Args:
            job_id: The job ID to cancel.

        Returns:
            True if the job was found and cancelled.
        """
        from rq.exceptions import NoSuchJobError
        from rq.job import Job as RQJob

        try:
            job = RQJob.fetch(job_id, connection=self.redis_client)
            job.cancel()
            logger.debug("Cancelled job %s", job_id)
            return True
        except NoSuchJobError:
            return False
        except Exception as e:
            logger.warning("Error cancelling job %s: %s", job_id, e)
            return False

    def get_queue_length(self) -> int:
        """Get number of pending jobs in the RQ queue."""
        return len(self.queue)

    def get_active_jobs(self) -> list[JobInfo]:
        """Get currently executing jobs from the started job registry."""
        from rq.job import Job as RQJob

        results = []
        try:
            registry = self.queue.started_job_registry
            job_ids = registry.get_job_ids()
            for jid in job_ids:
                try:
                    job = RQJob.fetch(jid, connection=self.redis_client)
                    results.append(_rq_job_to_info(job))
                except Exception:
                    pass
        except Exception as e:
            logger.debug("Error fetching active jobs: %s", e)
        return results

    def get_failed_jobs(self, limit: int = 50) -> list[JobInfo]:
        """Get failed jobs from the failed job registry.

        Args:
            limit: Maximum number of failed jobs to return.
        """
        from rq.job import Job as RQJob

        results = []
        try:
            registry = self.queue.failed_job_registry
            job_ids = registry.get_job_ids(0, limit)
            for jid in job_ids:
                try:
                    job = RQJob.fetch(jid, connection=self.redis_client)
                    results.append(_rq_job_to_info(job))
                except Exception:
                    pass
        except Exception as e:
            logger.debug("Error fetching failed jobs: %s", e)
        return results

    def clear_failed(self) -> int:
        """Clear all failed jobs from the registry.

        Returns:
            Number of failed jobs cleared.
        """
        try:
            registry = self.queue.failed_job_registry
            job_ids = registry.get_job_ids()
            count = len(job_ids)
            for jid in job_ids:
                registry.remove(jid, delete_job=True)
            if count > 0:
                logger.info("Cleared %d failed jobs from RQ", count)
            return count
        except Exception as e:
            logger.warning("Error clearing failed jobs: %s", e)
            return 0

    def get_backend_info(self) -> dict:
        """Get RQ backend status information.

        Returns:
            Dict with type, redis_url, queue_name, workers, queue_length,
            and a note about the worker requirement.
        """
        from rq import Worker

        info = {
            "type": "rq",
            "queue_name": self.queue_name,
            "queue_length": len(self.queue),
            "note": "RQ requires a separate 'rq worker' process to execute jobs",
        }

        try:
            workers = Worker.all(connection=self.redis_client)
            info["workers"] = len(workers)
            info["worker_names"] = [w.name for w in workers[:10]]
        except Exception as e:
            info["workers"] = 0
            info["worker_error"] = str(e)

        return info
