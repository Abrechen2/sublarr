---
phase: 22-bulk-auto-sync
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/routes/tools.py
  - backend/routes/library.py
  - backend/config.py
  - backend/db/config.py
autonomous: true

must_haves:
  truths:
    - "User can trigger auto-sync (alass or ffsubsync) for a single subtitle file from Library, Series Detail, or Editor (API)"
    - "User can trigger bulk auto-sync for an entire series or the entire library"
    - "Bulk sync runs as a background job with real-time WebSocket progress (current file, completed, failed)"
    - "User can choose sync engine (alass or ffsubsync) per operation or globally in Settings"
    - "Every sync operation creates a .bak backup of the original subtitle before modifying"
  artifacts:
    - path: "backend/routes/tools.py"
      provides: "POST /tools/auto-sync (single file), POST /tools/auto-sync/bulk; alass/ffsubsync subprocess; .bak backup"
    - path: "backend/db/config.py"
      provides: "Config entries for default sync engine (alass|ffsubsync)"
  key_links:
    - from: "backend/routes/tools.py"
      to: "_create_backup"
      via: "backup before sync"
    - from: "backend/routes/tools.py"
      to: "socketio.emit"
      via: "sync_batch_progress, sync_batch_complete"
---

<objective>
Backend: single-file and bulk subtitle timing sync via alass/ffsubsync; background job with WebSocket progress; .bak backup per file.

Purpose: Align subtitle timing to audio/video using alass or ffsubsync. Single-file sync from API; bulk sync for series or library with progress events. Every sync creates a .bak backup.

Output: POST /tools/auto-sync (single file, body: file_path, media_path or reference, engine optional); POST /tools/auto-sync/bulk (series_id or library scope, engine optional); subprocess integration for alass and ffsubsync; config for default engine; WebSocket events sync_batch_progress, sync_batch_complete.
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md

@backend/routes/tools.py
@backend/routes/wanted.py
@backend/routes/translate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Single-file auto-sync endpoint and alass/ffsubsync</name>
  <files>
    backend/routes/tools.py
  </files>
  <action>
1. Add POST /api/v1/tools/auto-sync: body { file_path, media_path? (video for reference), engine?: "alass"|"ffsubsync" }. Resolve media_path from file_path (same dir, same base name, common video extensions) if not provided.
2. Before sync: call _create_backup(file_path) to create .bak. Run alass or ffsubsync via subprocess (e.g. alass <ref_video> <sub_file> or ffsubsync <ref> <sub> -o <sub>). Write output to subtitle file. Return { status, error? }.
3. Config: sync_default_engine ("alass"|"ffsubsync") in config_entries; use when engine not in request. Validate engine availability (which alass/ffsubsync on PATH) or document Docker dependency.
  </action>
  <verify>
    Run backend tests. Manual: POST with test file and video; confirm .bak exists and subtitle timing updated (or mock subprocess).
  </verify>
  <done>
    Single-file auto-sync endpoint implemented; .bak created; alass/ffsubsync invoked; config for default engine.
  </done>
</task>

<task type="auto">
  <name>Task 2: Bulk sync and WebSocket progress</name>
  <files>
    backend/routes/tools.py
  </files>
  <action>
1. Add POST /api/v1/tools/auto-sync/bulk: body { scope: "series"|"library", series_id?: number }. Resolve list of subtitle files (from library scan or series episodes). Run in background (thread or existing job queue): for each file, resolve media path, _create_backup, run sync, emit socketio.emit("sync_batch_progress", { current, total, file_path, completed, failed, error? }). On finish emit socketio.emit("sync_batch_complete", { completed, failed, total }).
2. Use same engine selection: request body engine or config default. On subprocess failure for a file, increment failed and continue; include error in progress payload.
  </action>
  <verify>
    Trigger bulk sync for small series; confirm progress events and final complete event; .bak per file.
  </verify>
  <done>
    Bulk sync endpoint and background loop; sync_batch_progress and sync_batch_complete events; per-file backup.
  </done>
</task>

<task type="auto">
  <name>Task 3: Resolve subtitle and media file lists</name>
  <files>
    backend/routes/tools.py
    backend/routes/library.py
  </files>
  <action>
1. For scope=library: obtain all subtitle files from library (reuse library scan or DB of known files). For scope=series with series_id: obtain episode subtitle files for that series (from Sonarr or library index).
2. Each item: subtitle file path + corresponding media (video) path for alass/ffsubsync reference. Skip if no media found or file not accessible.
  </action>
  <verify>
    Bulk with scope=series returns correct file count; scope=library uses library data.
  </verify>
  <done>
    File list resolution for series and library implemented.
  </done>
</task>

</tasks>

<verification>
1. POST /tools/auto-sync: single file sync with .bak; engine from body or config.
2. POST /tools/auto-sync/bulk: background job; sync_batch_progress and sync_batch_complete; .bak per file.
3. Config: sync_default_engine (alass|ffsubsync).
</verification>

<success_criteria>
- Single-file and bulk auto-sync work via API; engine selectable.
- Bulk sync reports progress via WebSocket; every sync creates .bak.
</success_criteria>

<output>
After completion, create `.planning/phases/22-bulk-auto-sync/22-01-SUMMARY.md`
</output>
