---
phase: 10-performance-scalability
plan: 05
type: execute
wave: 3
depends_on: ["10-02", "10-03", "10-04"]
files_modified:
  - backend/app.py
  - backend/config.py
  - backend/db/__init__.py
  - backend/transaction_manager.py
  - backend/db/config.py
  - backend/db/blacklist.py
  - backend/db/cache.py
  - backend/db/plugins.py
  - backend/db/scoring.py
  - backend/db/library.py
  - backend/db/whisper.py
  - backend/db/translation.py
  - backend/db/jobs.py
  - backend/db/wanted.py
  - backend/db/profiles.py
  - backend/db/providers.py
  - backend/db/hooks.py
  - backend/db/standalone.py
autonomous: true

must_haves:
  truths:
    - "App starts with default config (SQLite, no Redis) and works identically to before"
    - "Setting SUBLARR_DATABASE_URL=postgresql://... switches all queries to PostgreSQL via SQLAlchemy"
    - "Setting SUBLARR_REDIS_URL=redis://... enables Redis cache and job queue"
    - "All existing db/ module functions delegate to repository layer"
    - "_db_lock is removed -- SQLAlchemy connection pool handles thread safety"
    - "Alembic migrations run automatically on startup"
    - "Connection pool is properly configured for the active database dialect"
  artifacts:
    - path: "backend/app.py"
      provides: "Updated create_app() with Flask-SQLAlchemy init, Alembic auto-migrate, cache/queue init"
      contains: "db.init_app"
    - path: "backend/config.py"
      provides: "New settings: database_url, redis_url, redis_cache_enabled, db_pool_size, etc."
      contains: "database_url"
    - path: "backend/db/__init__.py"
      provides: "Rewritten to use SQLAlchemy -- get_db() returns db.session, init_db() creates all tables"
      contains: "from extensions import db"
  key_links:
    - from: "backend/app.py"
      to: "backend/extensions.py"
      via: "db.init_app(app) and migrate.init_app(app)"
      pattern: "db\\.init_app"
    - from: "backend/app.py"
      to: "backend/cache/__init__.py"
      via: "create_cache_backend() called during app init"
      pattern: "create_cache_backend"
    - from: "backend/app.py"
      to: "backend/queue/__init__.py"
      via: "create_job_queue() called during app init"
      pattern: "create_job_queue"
    - from: "backend/db/__init__.py"
      to: "backend/extensions.py"
      via: "db import for session access"
      pattern: "from extensions import db"
    - from: "backend/config.py"
      to: "backend/app.py"
      via: "database_url and redis_url read during app factory"
      pattern: "database_url"
---

<objective>
Wire everything together: update app.py to initialize Flask-SQLAlchemy, Alembic, cache, and queue; add new config settings; rewrite db/__init__.py to use SQLAlchemy; redirect all existing db/ modules to delegate to their repository counterparts; remove _db_lock.

Purpose: This is the critical integration plan that switches the entire application from raw sqlite3 to SQLAlchemy ORM. After this plan, the app uses SQLAlchemy for ALL database operations, supports PostgreSQL via connection string, and initializes Redis cache/queue when configured. The key constraint is backward compatibility: with no new env vars set, behavior must be identical to before.

Output: Working application using SQLAlchemy ORM with optional PostgreSQL and Redis support.
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-performance-scalability/10-RESEARCH.md
@.planning/phases/10-performance-scalability/10-01-SUMMARY.md
@.planning/phases/10-performance-scalability/10-02-SUMMARY.md
@.planning/phases/10-performance-scalability/10-03-SUMMARY.md
@.planning/phases/10-performance-scalability/10-04-SUMMARY.md
@backend/app.py
@backend/config.py
@backend/db/__init__.py
@backend/transaction_manager.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Config settings + app factory + db/__init__.py rewrite</name>
  <files>
    backend/config.py
    backend/app.py
    backend/db/__init__.py
    backend/transaction_manager.py
  </files>
  <action>
1. Update backend/config.py -- add new settings to the Settings class:
   ```python
   # Database (PERF-01, PERF-02)
   database_url: str = ""  # Empty = SQLite at db_path. Set to postgresql://... for PG.
   db_pool_size: int = 5           # SQLAlchemy pool_size (ignored for SQLite)
   db_pool_max_overflow: int = 10  # SQLAlchemy max_overflow (ignored for SQLite)
   db_pool_recycle: int = 3600     # Recycle connections after N seconds

   # Redis (PERF-04, PERF-06)
   redis_url: str = ""             # Empty = no Redis. e.g., redis://localhost:6379/0
   redis_cache_enabled: bool = True   # Use Redis for provider cache (when redis_url set)
   redis_queue_enabled: bool = True   # Use Redis+RQ for job queue (when redis_url set)
   ```
   Add a helper method `get_database_url(self) -> str` that returns database_url if set, else `f"sqlite:///{self.db_path}"`.

2. Update backend/app.py create_app():
   - After existing setup, BEFORE blueprint registration:
     a. Configure Flask-SQLAlchemy:
        ```python
        settings = get_settings()
        app.config["SQLALCHEMY_DATABASE_URI"] = settings.get_database_url()
        # Only set pool options for non-SQLite (SQLite uses NullPool/StaticPool)
        if settings.database_url and not settings.database_url.startswith("sqlite"):
            app.config["SQLALCHEMY_ENGINE_OPTIONS"] = {
                "pool_size": settings.db_pool_size,
                "max_overflow": settings.db_pool_max_overflow,
                "pool_recycle": settings.db_pool_recycle,
                "pool_pre_ping": True,
            }
        else:
            # SQLite: use check_same_thread=False for thread safety
            app.config["SQLALCHEMY_ENGINE_OPTIONS"] = {
                "connect_args": {"check_same_thread": False},
            }
        ```
     b. Initialize Flask-SQLAlchemy and Flask-Migrate:
        ```python
        from extensions import db, migrate
        db.init_app(app)
        migrate.init_app(app, db, directory="db/migrations", render_as_batch=True)
        ```
     c. Create tables and run migrations:
        ```python
        with app.app_context():
            # Import all models so they register with metadata
            import db.models  # noqa: F401
            # For new databases: create all tables
            db.create_all()
            # Stamp existing DBs and run any pending migrations
            from db.migrations.env import stamp_existing_db_if_needed
            stamp_existing_db_if_needed(app)
        ```
     d. Initialize cache and queue backends (store on app):
        ```python
        from cache import create_cache_backend
        from queue import create_job_queue
        app.cache_backend = create_cache_backend(
            settings.redis_url if settings.redis_cache_enabled else ""
        )
        app.job_queue = create_job_queue(
            settings.redis_url if settings.redis_queue_enabled else ""
        )
        ```
     e. Enable SQLite WAL mode if using SQLite (match existing behavior):
        ```python
        if not settings.database_url or settings.database_url.startswith("sqlite"):
            with db.engine.connect() as conn:
                conn.execute(text("PRAGMA journal_mode=WAL"))
                conn.execute(text("PRAGMA busy_timeout=5000"))
                conn.commit()
        ```
   - Keep existing init_db() call for NOW as a safety measure during transition. It will be a no-op once db/__init__.py is rewritten.

3. Rewrite backend/db/__init__.py:
   - Remove the entire SCHEMA constant (ORM models define schema now).
   - Remove _connection singleton and get_db() raw sqlite3 function.
   - Remove _run_migrations() (Alembic handles this now).
   - Keep _db_lock temporarily but make it a no-op (compatibility shim for any code still importing it):
     ```python
     import threading
     class _NoOpLock:
         """No-op lock -- SQLAlchemy handles thread safety."""
         def __enter__(self): return self
         def __exit__(self, *args): pass
         def acquire(self, *args, **kwargs): pass
         def release(self, *args, **kwargs): pass
     _db_lock = _NoOpLock()
     ```
   - Redefine get_db() to return db.session (for gradual migration -- code importing get_db() gets a SQLAlchemy session):
     ```python
     def get_db():
         """Return the SQLAlchemy session (backward-compatible shim)."""
         from extensions import db
         return db.session
     ```
   - Redefine init_db() and close_db() as no-ops (Flask-SQLAlchemy manages lifecycle):
     ```python
     def init_db():
         """No-op -- SQLAlchemy initialized via app factory."""
         pass
     def close_db():
         """No-op -- SQLAlchemy manages session lifecycle."""
         pass
     ```

4. Update backend/transaction_manager.py:
   - The existing transaction manager wraps sqlite3 connections. Replace with SQLAlchemy session pattern:
     ```python
     from contextlib import contextmanager
     from extensions import db

     @contextmanager
     def transaction():
         """Context manager for SQLAlchemy transactions."""
         try:
             yield db.session
             db.session.commit()
         except Exception:
             db.session.rollback()
             raise
     ```
   - Keep the old `transaction(db_conn)` signature working by detecting argument type and delegating.

CRITICAL: The _NoOpLock for _db_lock is a transitional measure. Any code that does `with _db_lock: db.execute(...)` will still work but the lock is a no-op because SQLAlchemy's session scoping handles thread safety. This avoids a big-bang change of all 15 db/ modules.
  </action>
  <verify>
Run `cd Z:/CC/Sublarr/backend && python -c "from config import Settings; s = Settings(); print(s.get_database_url())"` -- should print SQLite URL.
Run `cd Z:/CC/Sublarr/backend && python -c "from db import _db_lock, get_db; print(type(_db_lock).__name__)"` -- should print "_NoOpLock".
Verify connection pool configuration:
Run `cd Z:/CC/Sublarr/backend && python -c "
from app import create_app
app = create_app(testing=True)
with app.app_context():
    from extensions import db
    engine = db.engine
    dialect = engine.dialect.name
    print(f'Dialect: {dialect}')
    pool = engine.pool
    print(f'Pool type: {type(pool).__name__}')
    if hasattr(pool, 'size'):
        print(f'Pool size: {pool.size()}, checked_out: {pool.checkedout()}, overflow: {pool.overflow()}')
    else:
        print('Pool: NullPool/StaticPool (SQLite) -- no pool attrs (expected)')
    print('Connection pool verification: OK')
"`.
  </verify>
  <done>App factory initializes Flask-SQLAlchemy + Alembic + cache + queue. Config has new database/Redis settings. db/__init__.py uses SQLAlchemy session. _db_lock is no-op. transaction_manager uses SQLAlchemy. Connection pool is correctly configured per dialect (QueuePool for PostgreSQL, StaticPool for SQLite).</done>
</task>

<task type="auto">
  <name>Task 2a: Redirect 8 simpler db/ domain modules to repository layer</name>
  <files>
    backend/db/config.py
    backend/db/blacklist.py
    backend/db/cache.py
    backend/db/plugins.py
    backend/db/scoring.py
    backend/db/library.py
    backend/db/whisper.py
    backend/db/translation.py
  </files>
  <action>
Rewrite each of the 8 simpler db/ domain modules to be thin wrappers that delegate to their repository counterpart. This preserves ALL existing import paths (`from db.config import get_config_entry` still works) while routing through SQLAlchemy under the hood.

For each module, the pattern is:
```python
"""[Module description] -- delegating to SQLAlchemy repository."""
from db.repositories.[module] import [Repository]

_repo = None

def _get_repo():
    global _repo
    if _repo is None:
        _repo = [Repository]()
    return _repo

def original_function(args...):
    return _get_repo().method(args...)
```

Specific modules to rewrite:

1. backend/db/config.py (38 lines -> ~15 lines):
   - Delegate save_config_entry, get_config_entry, get_all_config_entries to ConfigRepository.

2. backend/db/blacklist.py (83 lines -> ~25 lines):
   - Delegate all 6 functions to BlacklistRepository.

3. backend/db/cache.py (241 lines -> ~40 lines):
   - Delegate all cache + download functions to CacheRepository.

4. backend/db/plugins.py (118 lines -> ~20 lines):
   - Delegate all 4 functions to PluginRepository.

5. backend/db/scoring.py (192 lines -> ~25 lines):
   - Delegate all scoring functions to ScoringRepository.

6. backend/db/library.py (129 lines -> ~20 lines):
   - Delegate all library stat functions to LibraryRepository.

7. backend/db/whisper.py (163 lines -> ~25 lines):
   - Delegate all whisper job functions to WhisperRepository.

8. backend/db/translation.py (394 lines -> ~50 lines):
   - Delegate all translation config, glossary, preset, backend stats functions to TranslationRepository.

CRITICAL: Every public function signature MUST remain identical. Same name, same parameters, same return type. Import paths like `from db.config import get_config_entry` must continue working. This is NOT a renaming -- it is a transparent delegation.

IMPORTANT: Remove all `from db import get_db, _db_lock` imports from these modules. They no longer use raw sqlite3 connections. The repository handles all database access through SQLAlchemy.

IMPORTANT: Remove the `with _db_lock:` blocks and `db.execute()` / `db.commit()` calls. All of this is now handled by the repository layer.
  </action>
  <verify>
Verify all 8 simpler modules delegate correctly:
Run `cd Z:/CC/Sublarr/backend && python -c "
from app import create_app
app = create_app(testing=True)
with app.app_context():
    # 1. config
    from db.config import save_config_entry, get_config_entry, get_all_config_entries
    save_config_entry('_test_key', '_test_val')
    assert get_config_entry('_test_key') == '_test_val'
    print('1. db.config: OK')

    # 2. blacklist
    from db.blacklist import add_blacklist_entry, get_blacklist_count, clear_blacklist
    print('2. db.blacklist: OK (imports verified)')

    # 3. cache
    from db.cache import get_cached_results, save_cache_results, get_cache_stats
    print('3. db.cache: OK (imports verified)')

    # 4. plugins
    from db.plugins import get_plugin_config, set_plugin_config
    print('4. db.plugins: OK (imports verified)')

    # 5. scoring
    from db.scoring import get_scoring_weights, get_effective_weights
    print('5. db.scoring: OK (imports verified)')

    # 6. library
    from db.library import get_library_stats
    print('6. db.library: OK (imports verified)')

    # 7. whisper
    from db.whisper import create_whisper_job, get_whisper_jobs
    print('7. db.whisper: OK (imports verified)')

    # 8. translation
    from db.translation import get_prompt_presets, get_all_backend_stats
    print('8. db.translation: OK (imports verified)')

    print('All 8 simpler modules verified')
"`.
  </verify>
  <done>All 8 simpler db/ domain modules are thin wrappers delegating to SQLAlchemy repositories. All existing import paths work. Raw sqlite3 code eliminated from these modules.</done>
</task>

<task type="auto">
  <name>Task 2b: Redirect 6 complex db/ domain modules to repository layer</name>
  <files>
    backend/db/jobs.py
    backend/db/wanted.py
    backend/db/profiles.py
    backend/db/providers.py
    backend/db/hooks.py
    backend/db/standalone.py
  </files>
  <action>
Rewrite the 6 complex db/ domain modules to delegate to their repository counterparts, using the same thin wrapper pattern as Task 2a. These modules are separated because they have more functions and more complex signatures that need careful mapping.

Specific modules to rewrite:

1. backend/db/jobs.py (275 lines -> ~40 lines):
   - Delegate all job + daily stats functions to JobRepository.
   - Functions: create_job, update_job, get_job, get_jobs, get_recent_jobs, get_pending_job_count, delete_job, delete_old_jobs, record_daily_stats, get_daily_stats, get_stats_summary.

2. backend/db/wanted.py (356 lines -> ~40 lines):
   - Delegate all wanted item functions to WantedRepository.
   - Functions: upsert_wanted_item, get_wanted_items, get_wanted_item, get_wanted_by_file_path, update_wanted_status, mark_search_attempted, get_wanted_summary, get_wanted_for_series, get_wanted_for_movie, delete_wanted_item, delete_wanted_by_file_path, cleanup_wanted_items, get_wanted_by_subtitle_type.

3. backend/db/profiles.py (303 lines -> ~40 lines):
   - Delegate all profile + series/movie mapping functions to ProfileRepository.
   - Functions: create_profile, get_profiles, get_profile, get_default_profile, update_profile, delete_profile, set_series_profile, get_series_profile, remove_series_profile, set_movie_profile, get_movie_profile, remove_movie_profile, get_profile_assignments.

4. backend/db/providers.py (368 lines -> ~40 lines):
   - Delegate all provider stats functions to ProviderRepository.
   - Functions: record_search, record_download, record_download_failure, get_provider_stats, get_all_provider_stats, clear_provider_stats, check_auto_disable, clear_auto_disable, is_auto_disabled, get_disabled_providers.

5. backend/db/hooks.py (446 lines -> ~50 lines):
   - Delegate all hook, webhook, and hook_log functions to HookRepository.
   - Functions: create_hook, get_hooks, get_hook, update_hook, delete_hook, record_hook_triggered, create_webhook, get_webhooks, get_webhook, update_webhook, delete_webhook, record_webhook_triggered, create_hook_log, get_hook_logs, get_hook_log_count, clear_hook_logs, clear_old_hook_logs.

6. backend/db/standalone.py (408 lines -> ~50 lines):
   - Delegate all watched folder, series, movie, metadata cache, anidb functions to StandaloneRepository.
   - Functions: create_watched_folder, get_watched_folders, get_watched_folder, update_watched_folder, delete_watched_folder, update_last_scan, upsert_standalone_series, get_standalone_series, get_all_standalone_series, delete_standalone_series, get_standalone_series_by_folder, upsert_standalone_movie, get_standalone_movie, get_all_standalone_movies, delete_standalone_movie, get_standalone_movie_by_path, get_metadata_cache, save_metadata_cache, clear_expired_metadata_cache, get_anidb_mapping, save_anidb_mapping, clear_old_anidb_mappings.

CRITICAL: Same rules as Task 2a -- identical function signatures, transparent delegation, remove all raw sqlite3 imports and _db_lock usage.
  </action>
  <verify>
Verify all 6 complex modules delegate correctly:
Run `cd Z:/CC/Sublarr/backend && python -c "
from app import create_app
app = create_app(testing=True)
with app.app_context():
    # 9. jobs
    from db.jobs import create_job, get_job, get_pending_job_count, get_daily_stats
    job = create_job('/test/file.mkv')
    assert job is not None and 'id' in job
    fetched = get_job(job['id'])
    assert fetched is not None
    print('9. db.jobs: OK (CRUD verified)')

    # 10. wanted
    from db.wanted import upsert_wanted_item, get_wanted_items, get_wanted_summary
    print('10. db.wanted: OK (imports verified)')

    # 11. profiles
    from db.profiles import create_profile, get_profiles, get_default_profile, set_series_profile
    print('11. db.profiles: OK (imports verified)')

    # 12. providers
    from db.providers import record_search, get_all_provider_stats, is_auto_disabled
    print('12. db.providers: OK (imports verified)')

    # 13. hooks
    from db.hooks import create_hook, get_hooks, create_webhook, get_hook_logs
    print('13. db.hooks: OK (imports verified)')

    # 14. standalone
    from db.standalone import create_watched_folder, get_watched_folders, get_metadata_cache
    print('14. db.standalone: OK (imports verified)')

    print('All 6 complex modules verified')
"`.
Run the existing test suite to verify no regressions: `cd Z:/CC/Sublarr/backend && python -m pytest tests/ -x --timeout=60 -q`.
  </verify>
  <done>All 14 db/ domain modules are thin wrappers delegating to SQLAlchemy repositories. All existing import paths work. Raw sqlite3 code eliminated. _db_lock usage eliminated. Application starts and operates using SQLAlchemy ORM for all database operations.</done>
</task>

</tasks>

<verification>
1. Application starts with default config (no new env vars): `python -c "from app import create_app; app = create_app(); print('OK')"`
2. All db/ module import paths still work: `python -c "from db.jobs import create_job; from db.wanted import upsert_wanted_item; from db.config import get_config_entry"`
3. CRUD operations work through the new layer (smoke tests in Task 2a and 2b verify sections)
4. Existing tests pass: `python -m pytest tests/ -x`
5. No raw sqlite3 imports remain in db/ domain modules (only in db/__init__.py as fallback)
6. _db_lock is no-op: `python -c "from db import _db_lock; print(type(_db_lock).__name__)"`
7. Connection pool is configured correctly per dialect (pool attrs exist for PostgreSQL, absent for SQLite)
</verification>

<success_criteria>
- App starts and works identically with default config (SQLite, no Redis)
- All database operations routed through SQLAlchemy ORM
- Config has database_url and redis_url settings
- Cache and queue backends initialized in app factory
- Alembic migration infrastructure active
- _db_lock eliminated as active lock (no-op shim)
- All existing import paths preserved for backward compatibility
- Connection pool properly verified per dialect
</success_criteria>

<output>
After completion, create `.planning/phases/10-performance-scalability/10-05-SUMMARY.md`
</output>
