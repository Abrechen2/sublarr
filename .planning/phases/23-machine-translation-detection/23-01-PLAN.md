---
phase: 23-machine-translation-detection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/providers/base.py
  - backend/providers/opensubtitles.py
  - backend/wanted_search.py
  - backend/db/config.py
autonomous: true

must_haves:
  truths:
    - "Downloaded subtitle metadata and text patterns are analyzed to detect likely machine translation"
    - "Detected MT subtitles receive a configurable score penalty (default -30) before download decision"
    - "MT detection result (confidence %) is available for provider search results API"
    - "User can configure MT score penalty (0 = disabled) and confidence threshold in Settings Providers"
  artifacts:
    - path: "backend/providers/base.py"
      provides: "MT penalty in compute_score when result has machine_translated flag/confidence"
    - path: "backend/providers/opensubtitles.py"
      provides: "Read attributes.machine_translated, attributes.ai_translated; set on SubtitleResult"
    - path: "backend/wanted_search.py"
      provides: "_result_to_dict_interactive includes machine_translated, mt_confidence"
  key_links:
    - from: "backend/providers/__init__.py"
      to: "backend/providers/base.py"
      via: "compute_score with MT penalty"
    - from: "backend/providers/opensubtitles.py"
      to: "SubtitleResult.provider_data or new fields"
      via: "machine_translated, ai_translated"
---

<objective>
Backend: detect likely machine-translated provider subtitles; apply configurable score penalty; expose MT flag/confidence in search results.

Purpose: Prefer human-translated subtitles by penalizing detected MT; show MT badge in search UI. OpenSubtitles provides machine_translated/ai_translated; other providers can add heuristics later.

Output: OpenSubtitles populates MT metadata on SubtitleResult; compute_score applies penalty when MT detected above threshold; config for penalty and confidence threshold; wanted_search exports MT info in interactive search response.
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md

@backend/providers/base.py
@backend/providers/opensubtitles.py
@backend/wanted_search.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: OpenSubtitles MT metadata on SubtitleResult</name>
  <files>
    backend/providers/opensubtitles.py
    backend/providers/base.py
  </files>
  <action>
1. In OpenSubtitles provider: when parsing API response, read attributes.machine_translated and attributes.ai_translated (boolean or string). Set on SubtitleResult: either extend SubtitleResult with optional machine_translated: bool, mt_confidence: float (0-100), or store in provider_data dict and resolve in scoring.
2. If API gives only booleans, derive confidence (e.g. 100 when True, 0 when False); if API gives confidence, use it. Expose as consistent mt_confidence (0-100) for threshold comparison.
  </action>
  <verify>
    Unit test or fixture: OpenSubtitles response with machine_translated=true yields SubtitleResult with MT flag and confidence; compute_score receives it.
  </verify>
  <done>
    OpenSubtitles sets machine_translated and mt_confidence on results; SubtitleResult or provider_data carries them.
  </done>
</task>

<task type="auto">
  <name>Task 2: MT penalty in compute_score</name>
  <files>
    backend/providers/base.py
  </files>
  <action>
1. In compute_score(result, query): read config mt_penalty (int, default -30) and mt_confidence_threshold (float, default 50). If result has mt_confidence >= threshold (or machine_translated true when no confidence), add mt_penalty to score. When mt_penalty is 0, skip (feature disabled).
2. Config entries: providers.mt_penalty (int), providers.mt_confidence_threshold (float). Load in compute_score or once per request.
  </action>
  <verify>
    With mt_penalty=-30 and MT result, final score reduced by 30; with mt_penalty=0, no change.
  </verify>
  <done>
    compute_score applies configurable MT penalty when MT detected above threshold.
  </done>
</task>

<task type="auto">
  <name>Task 3: Expose MT in interactive search response</name>
  <files>
    backend/wanted_search.py
  </files>
  <action>
1. In _result_to_dict_interactive (or equivalent): add machine_translated: bool, mt_confidence: number when present on SubtitleResult. Frontend will show badge and confidence %.
  </action>
  <verify>
    GET /wanted/:id/search-providers (or episode search) response includes machine_translated and mt_confidence for OpenSubtitles results when applicable.
  </verify>
  <done>
    Search results API includes MT flag and confidence for UI badge.
  </done>
</task>

</tasks>

<verification>
1. OpenSubtitles results carry machine_translated and mt_confidence.
2. compute_score applies mt_penalty when mt_confidence >= threshold; mt_penalty=0 disables.
3. Interactive search response includes machine_translated, mt_confidence.
4. Config: providers.mt_penalty, providers.mt_confidence_threshold.
</verification>

<success_criteria>
- MT detection from OpenSubtitles metadata; configurable penalty and threshold.
- MT result visible in search results for frontend badge.
</success_criteria>

<output>
After completion, create `.planning/phases/23-machine-translation-detection/23-01-SUMMARY.md`
</output>
