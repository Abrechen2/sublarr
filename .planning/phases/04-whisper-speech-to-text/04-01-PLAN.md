---
phase: 04-whisper-speech-to-text
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/whisper/__init__.py
  - backend/whisper/base.py
  - backend/whisper/audio.py
  - backend/whisper/queue.py
  - backend/whisper/faster_whisper_backend.py
  - backend/whisper/subgen_backend.py
  - backend/db/__init__.py
  - backend/db/whisper.py
autonomous: true

must_haves:
  truths:
    - "WhisperManager can register and create backend instances by name"
    - "Audio extraction selects the correct language track via ffprobe and extracts to 16kHz mono WAV"
    - "WhisperQueue enforces max-concurrent limit via Semaphore and tracks job progress"
    - "faster-whisper backend transcribes audio to SRT with VAD filtering"
    - "Subgen backend sends audio to external /asr endpoint and returns SRT"
    - "whisper_jobs table stores job state with progress, status, and result"
  artifacts:
    - path: "backend/whisper/base.py"
      provides: "WhisperBackend ABC and TranscriptionResult dataclass"
      exports: ["WhisperBackend", "TranscriptionResult"]
    - path: "backend/whisper/__init__.py"
      provides: "WhisperManager singleton with registry and circuit breakers"
      exports: ["WhisperManager", "get_whisper_manager", "invalidate_whisper_manager"]
    - path: "backend/whisper/audio.py"
      provides: "Audio track selection (ffprobe) and extraction (ffmpeg)"
      exports: ["select_audio_track", "extract_audio_to_wav"]
    - path: "backend/whisper/queue.py"
      provides: "WhisperQueue with Semaphore concurrency and progress tracking"
      exports: ["WhisperQueue", "WhisperJob"]
    - path: "backend/whisper/faster_whisper_backend.py"
      provides: "Local faster-whisper transcription backend"
      exports: ["FasterWhisperBackend"]
    - path: "backend/whisper/subgen_backend.py"
      provides: "External Subgen API transcription backend"
      exports: ["SubgenBackend"]
    - path: "backend/db/whisper.py"
      provides: "whisper_jobs table CRUD operations"
      exports: ["create_whisper_job", "update_whisper_job", "get_whisper_job", "get_whisper_jobs", "get_whisper_stats"]
  key_links:
    - from: "backend/whisper/__init__.py"
      to: "backend/whisper/base.py"
      via: "import WhisperBackend"
      pattern: "from whisper\\.base import"
    - from: "backend/whisper/__init__.py"
      to: "backend/circuit_breaker.py"
      via: "CircuitBreaker per backend"
      pattern: "from circuit_breaker import CircuitBreaker"
    - from: "backend/whisper/queue.py"
      to: "backend/db/whisper.py"
      via: "job state persistence"
      pattern: "from db\\.whisper import"
    - from: "backend/whisper/faster_whisper_backend.py"
      to: "backend/whisper/base.py"
      via: "inherits WhisperBackend"
      pattern: "class FasterWhisperBackend\\(WhisperBackend\\)"
    - from: "backend/whisper/subgen_backend.py"
      to: "backend/whisper/base.py"
      via: "inherits WhisperBackend"
      pattern: "class SubgenBackend\\(WhisperBackend\\)"
---

<objective>
Create the complete whisper/ package with WhisperBackend ABC, WhisperManager singleton, audio extraction utilities, queue system, database schema, and both backend implementations (faster-whisper local + Subgen API external).

Purpose: This is the foundational package for Whisper speech-to-text, following the same ABC + Manager + circuit breaker pattern established in Phase 2 (translation/) and Phase 3 (mediaserver/). It provides the complete backend subsystem that Plans 02 and 03 will wire into the application.

Output: Self-contained whisper/ package with 6 modules + db/whisper.py for job persistence + schema DDL in db/__init__.py
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-whisper-speech-to-text/04-RESEARCH.md

Key pattern references (read these for structure to mirror):
@backend/translation/base.py (TranslationBackend ABC pattern)
@backend/translation/__init__.py (TranslationManager singleton pattern)
@backend/mediaserver/base.py (MediaServer ABC with config_fields)
@backend/mediaserver/__init__.py (MediaServerManager with JSON config)
@backend/db/__init__.py (SCHEMA DDL and table definitions)
@backend/db/translation.py (backend stats CRUD pattern)
@backend/providers/whisper_subgen.py (existing Subgen audio extraction to reuse/improve)
</context>

<tasks>

<task type="auto">
  <name>Task 1: WhisperBackend ABC, Manager, audio extraction, queue, and DB schema</name>
  <files>
    backend/whisper/__init__.py
    backend/whisper/base.py
    backend/whisper/audio.py
    backend/whisper/queue.py
    backend/db/__init__.py
    backend/db/whisper.py
  </files>
  <action>
    Create the whisper/ package directory and 4 core modules.

    **backend/whisper/base.py** -- Mirror translation/base.py structure:
    - TranscriptionResult dataclass with fields: srt_content (str), detected_language (str), language_probability (float), duration_seconds (float), segment_count (int), backend_name (str), processing_time_ms (float), error (Optional[str]), success (bool=True)
    - WhisperBackend ABC with class-level attributes: name, display_name, config_fields (same format as TranslationBackend), supports_gpu (bool), supports_language_detection (bool=True)
    - Constructor: __init__(self, **config) storing self.config = config
    - Abstract methods: transcribe(audio_path, language="", task="transcribe", progress_callback=None) -> TranscriptionResult, health_check() -> tuple[bool, str], get_available_models() -> list[dict]
    - Non-abstract method: get_config_fields() -> list[dict] returning cls.config_fields (same pattern as TranslationBackend)

    **backend/whisper/__init__.py** -- Mirror translation/__init__.py structure:
    - WhisperManager class with: _backend_classes dict, _backend (Optional[WhisperBackend] -- single active backend, NOT dict), _circuit_breaker (Optional[CircuitBreaker])
    - register_backend(cls) -- registers a backend class by name
    - get_backend(name) -- lazy creation from config_entries using whisper.<name>.<key> namespacing
    - get_active_backend() -- returns the currently configured backend (read whisper_backend config entry for which backend to use)
    - get_all_backends() -- info about all registered backends (name, display_name, config_fields, configured)
    - transcribe(audio_path, language, progress_callback) -- delegates to active backend with circuit breaker
    - invalidate_backend() -- clears cached instance on config change
    - _load_backend_config(name) -- reads from config_entries with whisper.<name>.<key> prefix (same pattern as TranslationManager._load_backend_config)
    - Singleton: get_whisper_manager(), invalidate_whisper_manager()
    - _register_builtin_backends() -- registers FasterWhisperBackend (try/except ImportError) and SubgenBackend

    **backend/whisper/audio.py** -- Audio extraction utilities:
    - get_audio_streams(file_path) -> list[dict]: Run ffprobe with -select_streams a -print_format json -show_streams. Return list of stream dicts.
    - select_audio_track(file_path, preferred_language="ja") -> dict: Call get_audio_streams, match against preferred_language using ISO 639-1 and 639-2 tags (map "ja" -> ["ja", "jpn"], "en" -> ["en", "eng"], "de" -> ["de", "deu", "ger"], etc.). Return dict with stream_index, language, codec, channels. Fall back to first audio stream if no language match. Raise RuntimeError if no audio streams found.
    - extract_audio_to_wav(file_path, stream_index, output_path) -> str: Run ffmpeg with -map 0:a:{stream_index} -acodec pcm_s16le -ar 16000 -ac 1. Write to output_path. Return output_path. Use subprocess.run with timeout=300 (5 minutes for long files). Log the extraction with file size.
    - ISO 639 mapping: Use a LANGUAGE_TAG_MAP dict covering common anime languages (ja/jpn, en/eng, de/deu/ger, fr/fra/fre, es/spa, zh/zho/chi, ko/kor, pt/por, ru/rus, it/ita, ar/ara, nl/nld/dut, pl/pol, sv/swe). This avoids external dependency.

    **backend/whisper/queue.py** -- Queue system:
    - WhisperJob dataclass: job_id (str), file_path (str), language (str), status (str: queued/extracting/loading/transcribing/saving/completed/failed), progress (float 0-1), phase (str), result (Optional[TranscriptionResult]), error (Optional[str]), created_at (str), started_at (Optional[str]), completed_at (Optional[str])
    - WhisperQueue class:
      - __init__(max_concurrent=1): threading.Semaphore(max_concurrent), _jobs dict, _lock threading.Lock()
      - submit(job_id, file_path, language, source_language, whisper_manager, socketio=None) -> str: Create WhisperJob, persist to DB, start daemon thread, return job_id
      - get_job(job_id) -> Optional[WhisperJob]
      - get_all_jobs() -> list[WhisperJob]
      - cancel_job(job_id) -> bool: Set status to "cancelled" (best-effort, cannot interrupt transcription)
      - _run_job(job_id, file_path, language, source_language, whisper_manager, socketio): With self._semaphore context:
        1. Update status "extracting" (0-10%): Call audio.select_audio_track + audio.extract_audio_to_wav to temp file
        2. Update status "transcribing" (10-95%): Call whisper_manager.transcribe(audio_path, language, progress_callback)
        3. Progress callback: Maps Whisper segment progress to 10-95% range, emits socketio "whisper_progress" if socketio provided
        4. Update status "saving" (95-100%): Store result
        5. Update status "completed" (100%): Emit socketio "whisper_completed"
        6. On error: Update status "failed" with error message, emit socketio "whisper_error"
        7. Finally: Clean up temp audio file
      - _emit_progress(socketio, job_id, phase, progress, message): Emit WebSocket event if socketio is not None

    **backend/db/__init__.py** -- Add whisper_jobs table to SCHEMA string:
    ```sql
    CREATE TABLE IF NOT EXISTS whisper_jobs (
        id TEXT PRIMARY KEY,
        file_path TEXT NOT NULL,
        language TEXT NOT NULL DEFAULT '',
        status TEXT NOT NULL DEFAULT 'queued',
        progress REAL DEFAULT 0.0,
        phase TEXT DEFAULT '',
        backend_name TEXT DEFAULT '',
        detected_language TEXT DEFAULT '',
        language_probability REAL DEFAULT 0.0,
        srt_content TEXT DEFAULT '',
        segment_count INTEGER DEFAULT 0,
        duration_seconds REAL DEFAULT 0.0,
        processing_time_ms REAL DEFAULT 0.0,
        error TEXT DEFAULT '',
        created_at TEXT NOT NULL,
        started_at TEXT DEFAULT '',
        completed_at TEXT DEFAULT ''
    );
    CREATE INDEX IF NOT EXISTS idx_whisper_jobs_status ON whisper_jobs(status);
    CREATE INDEX IF NOT EXISTS idx_whisper_jobs_created ON whisper_jobs(created_at);
    ```

    **backend/db/whisper.py** -- CRUD for whisper_jobs table:
    - create_whisper_job(job_id, file_path, language) -> dict
    - update_whisper_job(job_id, **kwargs) -> None (accepts any column as kwarg)
    - get_whisper_job(job_id) -> Optional[dict]
    - get_whisper_jobs(status=None, limit=50) -> list[dict]
    - delete_whisper_job(job_id) -> bool
    - get_whisper_stats() -> dict (total, by_status counts, avg_processing_time)
    - Use the established _db_lock pattern from db/__init__.py for thread safety.
    - Use _row_to_job helper (same pattern as db/jobs.py _row_to_job).
  </action>
  <verify>
    python -c "from whisper.base import WhisperBackend, TranscriptionResult; print('ABC OK')"
    python -c "from whisper import get_whisper_manager; m = get_whisper_manager(); print(f'Manager OK, backends: {[b[\"name\"] for b in m.get_all_backends()]}')"
    python -c "from whisper.audio import get_audio_streams, select_audio_track, extract_audio_to_wav; print('Audio OK')"
    python -c "from whisper.queue import WhisperQueue, WhisperJob; print('Queue OK')"
    python -c "from db.whisper import create_whisper_job, get_whisper_job; print('DB OK')"
  </verify>
  <done>
    whisper/ package imports cleanly with ABC, Manager singleton, audio utilities, queue system, and DB CRUD. WhisperManager registers backends (even if faster-whisper not installed -- ImportError caught gracefully). All modules follow established patterns from translation/ and mediaserver/.
  </done>
</task>

<task type="auto">
  <name>Task 2: faster-whisper and Subgen backend implementations</name>
  <files>
    backend/whisper/faster_whisper_backend.py
    backend/whisper/subgen_backend.py
  </files>
  <action>
    Create both WhisperBackend implementations.

    **backend/whisper/faster_whisper_backend.py** -- Local faster-whisper backend:
    - Guard import: `try: from faster_whisper import WhisperModel; HAS_FASTER_WHISPER = True; except ImportError: HAS_FASTER_WHISPER = False`
    - Class FasterWhisperBackend(WhisperBackend):
      - name = "faster_whisper"
      - display_name = "Faster Whisper (Local)"
      - supports_gpu = True
      - config_fields = [
          {"key": "model_size", "label": "Model Size", "type": "text", "required": True, "default": "medium", "help": "Model: tiny, base, small, medium, large-v2, large-v3, distil-large-v3"},
          {"key": "device", "label": "Device", "type": "text", "required": False, "default": "auto", "help": "auto, cuda, or cpu"},
          {"key": "compute_type", "label": "Compute Type", "type": "text", "required": False, "default": "auto", "help": "float16, int8_float16, int8, float32, or auto"},
          {"key": "cpu_threads", "label": "CPU Threads", "type": "number", "required": False, "default": "4", "help": "Number of CPU threads (CPU mode only)"},
          {"key": "beam_size", "label": "Beam Size", "type": "number", "required": False, "default": "5", "help": "Beam search size (higher = more accurate, slower)"},
          {"key": "vad_filter", "label": "VAD Filter", "type": "text", "required": False, "default": "true", "help": "Enable Silero VAD for better accuracy (recommended for anime)"},
          {"key": "model_path", "label": "Model Storage Path", "type": "text", "required": False, "default": "/config/whisper-models", "help": "Directory for downloaded models"},
        ]
      - __init__(**config): Store config, set self._model = None (lazy load)
      - _get_or_load_model(): Lazy-load WhisperModel with config params. Cache in self._model. Only reload if model_size/device/compute_type changed. Log model loading time.
      - transcribe(audio_path, language, task, progress_callback) -> TranscriptionResult:
        - Load model via _get_or_load_model()
        - Call model.transcribe(audio_path, language=language or None, task=task, beam_size=beam_size, vad_filter=vad_filter, vad_parameters={"min_silence_duration_ms": 500, "speech_pad_ms": 400}, word_timestamps=False)
        - Iterate segments generator: build SRT content string, track segment count, call progress_callback with segment.end / info.duration ratio
        - Return TranscriptionResult with srt_content, detected_language=info.language, language_probability=info.language_probability, duration_seconds=info.duration, segment_count, processing_time_ms, backend_name=self.name
        - Use _format_srt_timestamp(seconds) helper: converts float seconds to "HH:MM:SS,mmm" format
      - health_check() -> tuple[bool, str]:
        - If not HAS_FASTER_WHISPER: return (False, "faster-whisper not installed")
        - Try loading model (or confirm cached model is loaded). Return (True, f"Model {model_size} loaded on {device}")
        - On error: return (False, str(e))
      - get_available_models() -> list[dict]:
        - Return static list: [{"name": "tiny", "size": "~150MB"}, {"name": "base", "size": "~300MB"}, {"name": "small", "size": "~900MB"}, {"name": "medium", "size": "~3GB"}, {"name": "large-v2", "size": "~6GB"}, {"name": "large-v3", "size": "~6GB"}, {"name": "distil-large-v3", "size": "~1.5GB"}]

    **backend/whisper/subgen_backend.py** -- External Subgen API backend:
    - Import requests (already a dependency, no guard needed)
    - Class SubgenBackend(WhisperBackend):
      - name = "subgen"
      - display_name = "Subgen (External API)"
      - supports_gpu = False (remote -- we don't know)
      - config_fields = [
          {"key": "endpoint", "label": "Subgen URL", "type": "text", "required": True, "default": "http://subgen:9000", "help": "URL of Subgen instance"},
          {"key": "timeout", "label": "Timeout (seconds)", "type": "number", "required": False, "default": "600", "help": "Request timeout for transcription"},
        ]
      - __init__(**config): Store endpoint (stripped trailing /), parse timeout as int (default 600)
      - transcribe(audio_path, language, task, progress_callback) -> TranscriptionResult:
        - Read audio file as bytes
        - If progress_callback: call progress_callback(0.1) (10% for upload start)
        - POST to {endpoint}/asr with params task=task, language=language, output=srt and files audio_file=(audio.wav, audio_bytes, audio/wav)
        - Timeout = self.timeout
        - If progress_callback: call progress_callback(0.9) (we can't track Subgen internal progress)
        - Parse response: resp.text is SRT content
        - Count segments (count "\n\n" blocks), estimate duration from last timestamp
        - Return TranscriptionResult with srt_content=resp.text, detected_language=language (Subgen doesn't return this separately), segment_count, backend_name=self.name
        - On error: return TranscriptionResult(success=False, error=str(e))
      - health_check() -> tuple[bool, str]:
        - Try GET {endpoint}/health with timeout=10. If 200: return (True, "OK")
        - Fallback: GET {endpoint}/ with timeout=10. If 200: return (True, "OK")
        - On error: return (False, f"Subgen not reachable at {endpoint}")
      - get_available_models() -> list[dict]:
        - Return empty list (models configured on Subgen side, not here)

    Both backends follow the exact same pattern as translation backends: config_fields declarative, try/except ImportError guard for optional deps, lazy initialization.
  </action>
  <verify>
    python -c "from whisper.faster_whisper_backend import FasterWhisperBackend; b = FasterWhisperBackend(model_size='medium'); print(f'FW OK, fields: {len(b.config_fields)}')"
    python -c "from whisper.subgen_backend import SubgenBackend; b = SubgenBackend(endpoint='http://test:9000'); print(f'Subgen OK, fields: {len(b.config_fields)}')"
    python -c "from whisper import get_whisper_manager; m = get_whisper_manager(); names = [b['name'] for b in m.get_all_backends()]; assert 'subgen' in names; print(f'Registered: {names}')"
  </verify>
  <done>
    Both Whisper backends implement the WhisperBackend ABC correctly. FasterWhisperBackend has lazy model loading with GPU/CPU selection and VAD support. SubgenBackend wraps the /asr HTTP endpoint. Both register in WhisperManager via _register_builtin_backends(). faster-whisper import failure is caught gracefully (Subgen still works).
  </done>
</task>

</tasks>

<verification>
- `python -c "from whisper import get_whisper_manager"` -- package imports without error
- `python -c "from whisper.base import WhisperBackend, TranscriptionResult"` -- ABC importable
- `python -c "from whisper.audio import select_audio_track, extract_audio_to_wav"` -- audio utils importable
- `python -c "from whisper.queue import WhisperQueue"` -- queue importable
- `python -c "from db.whisper import create_whisper_job, get_whisper_jobs"` -- DB CRUD importable
- WhisperManager.get_all_backends() returns at least "subgen" (faster_whisper may be missing if not installed)
- No import errors on application startup
</verification>

<success_criteria>
- Complete whisper/ package with 6 modules following ABC + Manager + circuit breaker pattern
- WhisperManager singleton with lazy backend creation and config_entries integration
- Audio extraction correctly uses ffprobe for track selection and ffmpeg for WAV extraction
- WhisperQueue manages concurrency via Semaphore and emits WebSocket progress events
- whisper_jobs DB table created with proper schema and CRUD operations
- Both backends (faster-whisper + Subgen) implement the ABC and are registered in the manager
- faster-whisper is optional dependency (ImportError caught gracefully)
</success_criteria>

<output>
After completion, create `.planning/phases/04-whisper-speech-to-text/04-01-SUMMARY.md`
</output>
