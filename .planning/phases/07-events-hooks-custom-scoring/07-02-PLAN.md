---
phase: 07-events-hooks-custom-scoring
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - backend/events/hooks.py
  - backend/events/webhooks.py
  - backend/routes/config.py
  - backend/routes/translate.py
  - backend/routes/wanted.py
  - backend/routes/webhooks.py
  - backend/wanted_scanner.py
  - backend/whisper/queue.py
  - backend/standalone/__init__.py
  - backend/app.py
autonomous: true

must_haves:
  truths:
    - "Shell scripts execute on configured events with SUBLARR_ prefixed environment variables and configurable timeout"
    - "Outgoing webhooks fire HTTP POST with JSON payload, HMAC signature, and exponential backoff retry"
    - "Hook and webhook execution is async (ThreadPoolExecutor) — never blocks the event producer"
    - "All 22+ existing socketio.emit calls are replaced by event bus emit_event calls"
    - "WebSocket clients still receive the same events via the SocketIO bridge (backward compatible)"
    - "Hook/webhook execution results are logged to the hook_log table"
  artifacts:
    - path: "backend/events/hooks.py"
      provides: "HookEngine with shell script execution, ThreadPoolExecutor dispatch"
      exports: ["HookEngine", "init_hook_subscribers"]
    - path: "backend/events/webhooks.py"
      provides: "WebhookDispatcher with HTTP POST, HMAC signing, retry logic"
      exports: ["WebhookDispatcher", "init_webhook_subscribers"]
    - path: "backend/app.py"
      provides: "init_event_system called during app creation"
      contains: "init_event_system"
  key_links:
    - from: "backend/events/hooks.py"
      to: "backend/events/catalog.py"
      via: "subscribes to signals from EVENT_CATALOG"
      pattern: "signal\\.connect"
    - from: "backend/events/webhooks.py"
      to: "backend/events/catalog.py"
      via: "subscribes to signals from EVENT_CATALOG"
      pattern: "signal\\.connect"
    - from: "backend/events/hooks.py"
      to: "backend/db/hooks.py"
      via: "reads hook_configs, writes hook_log"
      pattern: "from db\\.hooks import"
    - from: "backend/routes/wanted.py"
      to: "backend/events"
      via: "emit_event replaces socketio.emit"
      pattern: "from events import emit_event"
    - from: "backend/app.py"
      to: "backend/events"
      via: "init_event_system called in create_app"
      pattern: "from events import init_event_system"
---

<objective>
Build the hook execution engine (shell scripts) and webhook dispatcher (HTTP POST with retry), then rewire all 22+ existing socketio.emit calls to use the event bus. After this plan, the event system is fully operational end-to-end: events fire -> SocketIO bridge + hooks + webhooks all receive them.

Purpose: This is the core execution layer. Plan 01 defined what events exist and how to store configurations; this plan makes them actually fire. The socketio.emit rewiring is the critical integration step that connects the event bus to the real application flow.

Output: events/hooks.py, events/webhooks.py, all socketio.emit call sites rewired, app.py updated
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-events-hooks-custom-scoring/07-RESEARCH.md
@.planning/phases/07-events-hooks-custom-scoring/07-01-SUMMARY.md

@backend/app.py
@backend/events/__init__.py
@backend/events/catalog.py
@backend/db/hooks.py
@backend/extensions.py
@backend/routes/config.py
@backend/routes/translate.py
@backend/routes/wanted.py
@backend/routes/webhooks.py
@backend/wanted_scanner.py
@backend/whisper/queue.py
@backend/standalone/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build HookEngine and WebhookDispatcher with async execution</name>
  <files>backend/events/hooks.py, backend/events/webhooks.py</files>
  <action>
**events/hooks.py** — HookEngine class:

1. Create `HookEngine` class with:
   - `__init__(self, max_workers=4)`: Create `ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="hook")`
   - `execute_hook(self, hook_config: dict, event_data: dict) -> dict`: Execute a single hook synchronously (called inside thread pool):
     - Validate script_path exists and is a file (os.path.isfile). If not, return error dict.
     - Build controlled environment: PATH from os.environ, HOME=/tmp, SUBLARR_EVENT=event_name, SUBLARR_EVENT_DATA=json.dumps(event_data). For each key in event_data, add SUBLARR_{KEY.upper()}=str(value). Limit env var values to 4096 chars.
     - Execute with `subprocess.run([script_path], env=hook_env, timeout=hook_config['timeout_seconds'], capture_output=True, text=True, cwd="/tmp")`. NO shell=True.
     - Return dict: success (bool), exit_code (int), stdout (str, truncated to 4096), stderr (str, truncated to 4096), duration_ms (float)
     - Catch subprocess.TimeoutExpired -> success=False, error="Timeout after Ns"
     - Catch all other exceptions -> success=False, error=str(e)
   - `dispatch(self, event_name: str, event_data: dict)`: Async dispatch to thread pool:
     - Import get_hook_configs from db.hooks (lazy import)
     - Get all enabled hook_configs for this event_name
     - For each config: submit `_execute_and_log(config, event_name, event_data)` to thread pool
   - `_execute_and_log(self, config, event_name, event_data)`: Internal method:
     - Call execute_hook
     - Call log_hook_execution from db.hooks with the result
     - Call update_hook_trigger_stats from db.hooks
     - Emit hook_executed signal from catalog (meta-event)
   - `shutdown(self)`: Shutdown thread pool gracefully

2. Create `init_hook_subscribers(engine: HookEngine)` function:
   - Import EVENT_CATALOG from events.catalog
   - For each event in EVENT_CATALOG: subscribe engine.dispatch to that signal using closure pattern
   - Log at INFO level how many events have hook subscribers

**events/webhooks.py** — WebhookDispatcher class:

1. Create `_create_webhook_session() -> requests.Session`:
   - Set User-Agent: "Sublarr-Webhook/1.0", Content-Type: "application/json"
   - Configure urllib3 Retry: total=3 (configurable per webhook), backoff_factor=2 (2s, 4s, 8s), status_forcelist=[429, 500, 502, 503, 504], allowed_methods=["POST"]
   - Mount HTTPAdapter on https:// and http://

2. Create `WebhookDispatcher` class with:
   - `__init__(self, max_workers=4)`: Create `ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="webhook")`
   - `send_webhook(self, webhook_config: dict, event_data: dict) -> dict`: Send webhook synchronously (called inside thread pool):
     - Build payload: `{"event_name": event_name, "version": 1, "timestamp": ISO datetime, "data": event_data}`
     - Build headers: X-Sublarr-Event: event_name
     - If webhook_config['secret']: compute HMAC-SHA256 of JSON body, add X-Sublarr-Signature: "sha256={hex}"
     - Create session with retry_count from config, POST to url with timeout from config
     - Return dict: success (status < 400), status_code, duration_ms
     - Catch exceptions -> success=False, error=str(e)
   - `dispatch(self, event_name: str, event_data: dict)`: Async dispatch:
     - Import get_webhook_configs from db.hooks (lazy import)
     - Get all enabled webhook_configs matching event_name OR event_name="*" (wildcard)
     - Skip webhooks with consecutive_failures >= 10 (auto-disable, log warning)
     - For each: submit `_send_and_log(config, event_name, event_data)` to thread pool
   - `_send_and_log(self, config, event_name, event_data)`: Internal method:
     - Call send_webhook
     - Call log_hook_execution from db.hooks (with webhook_id, hook_type="webhook")
     - Call update_webhook_trigger_stats from db.hooks
   - `shutdown(self)`: Shutdown thread pool gracefully

3. Create `init_webhook_subscribers(dispatcher: WebhookDispatcher)` function:
   - Same pattern as init_hook_subscribers but for webhook dispatch
  </action>
  <verify>
```bash
cd backend && python -c "
from events.hooks import HookEngine, init_hook_subscribers
from events.webhooks import WebhookDispatcher, init_webhook_subscribers
engine = HookEngine(max_workers=2)
dispatcher = WebhookDispatcher(max_workers=2)
print('OK: HookEngine and WebhookDispatcher instantiate')
engine.shutdown()
dispatcher.shutdown()
print('OK: Shutdown clean')
"
```
  </verify>
  <done>HookEngine executes shell scripts via subprocess with timeout and controlled env; WebhookDispatcher sends HTTP POST with HMAC and retry; both dispatch async via ThreadPoolExecutor; both log results to hook_log table</done>
</task>

<task type="auto">
  <name>Task 2: Rewire all socketio.emit calls to use event bus and initialize in app.py</name>
  <files>backend/app.py, backend/routes/config.py, backend/routes/translate.py, backend/routes/wanted.py, backend/routes/webhooks.py, backend/wanted_scanner.py, backend/whisper/queue.py, backend/standalone/__init__.py</files>
  <action>
**Step 1: Update app.py** to call init_event_system during app creation:
- After `from db import init_db; init_db()` block and BEFORE blueprint registration, add:
  ```
  from events import init_event_system
  init_event_system(app)
  ```
- This ensures the SocketIO bridge + hook/webhook subscribers are active before any routes fire events

**Step 2: Rewire socketio.emit calls across all files.** For each file, replace `socketio.emit("event_name", data)` with `emit_event("event_name", data)`. Import `from events import emit_event` at the top of each file. Remove unused `from extensions import socketio` imports ONLY if socketio is no longer used in that file for anything else (some files use socketio for SocketIO event handlers like @socketio.on — keep those imports).

File-by-file rewiring (all 22+ call sites):

**routes/config.py** (~1 call):
- `socketio.emit("config_updated", {"updated_keys": saved_keys})` -> `emit_event("config_updated", {"updated_keys": saved_keys})`
- Also: after config_updated, call `invalidate_scoring_cache()` from providers.base if scoring-related keys changed (weight keys start with "scoring_" or "provider_modifier_")

**routes/translate.py** (~6 calls):
- `socketio.emit("job_update", {...})` -> `emit_event("job_update", {...})` (Note: job_update is an operational event, add it to EVENT_CATALOG in catalog.py if not already present, OR keep as direct socketio.emit since it's a progress stream not a business event. Decision: Keep job_update, batch_progress, retranslation_progress as direct socketio.emit calls since they are high-frequency progress streams that hooks/webhooks should NOT subscribe to. Only rewire the completion/error events.)
- Rewire: `socketio.emit("batch_completed", ...)` -> `emit_event("batch_complete", ...)`
- Rewire: `socketio.emit("retranslation_completed", ...)` -> `emit_event("translation_complete", ...)`
- Keep as socketio.emit (progress streams): job_update, batch_progress, retranslation_progress

**routes/wanted.py** (~6 calls):
- `socketio.emit("wanted_scan_completed", result)` -> `emit_event("wanted_scan_complete", result)`
- `socketio.emit("wanted_item_processed", result)` -> `emit_event("wanted_item_processed", result)`
- `socketio.emit("upgrade_completed", {...})` -> `emit_event("upgrade_complete", {...})`
- `socketio.emit("wanted_batch_completed", ...)` -> `emit_event("batch_complete", ...)`
- Keep as socketio.emit (progress streams): wanted_batch_progress

**routes/webhooks.py** (~2 calls):
- `socketio.emit("webhook_received", {...})` -> `emit_event("webhook_received", {...})`
- `socketio.emit("webhook_completed", ...)` -> Keep as socketio.emit (operational, not a catalog event) OR add as separate event. Decision: emit_event("webhook_received", ...) for the incoming webhook, keep webhook_completed as socketio.emit.

**wanted_scanner.py** (~2 calls):
- `socketio.emit("wanted_search_completed", summary)` -> `emit_event("wanted_scan_complete", summary)`
- Keep as socketio.emit (progress): wanted_search_progress

**whisper/queue.py** (~3 calls):
- `socketio.emit("whisper_completed", {...})` -> `emit_event("whisper_complete", {...})`
- `socketio.emit("whisper_error", {...})` -> `emit_event("whisper_failed", {...})`
- Keep as socketio.emit (progress): whisper_progress

**standalone/__init__.py** (~2 calls):
- `self._socketio.emit("standalone_scan_complete", summary)` -> Use emit_event. Import emit_event at module level. Replace self._socketio.emit with emit_event call. Note: the standalone manager stores socketio ref — emit_event should work without it.
- `self._socketio.emit("standalone_file_detected", {...})` -> `emit_event("standalone_file_detected", {...})` (add to EVENT_CATALOG if needed, or keep as socketio.emit since it's operational)

**Important rules for rewiring:**
- Progress/streaming events (job_update, batch_progress, wanted_batch_progress, retranslation_progress, wanted_search_progress, whisper_progress) stay as direct socketio.emit — they fire at high frequency and should NOT trigger hooks/webhooks
- Completion/failure events get rewired to emit_event — they are business events hooks/webhooks should respond to
- The SocketIO bridge in events/__init__.py ensures WebSocket clients still receive all rewired events (backward compat)
- Add any missing event names to EVENT_CATALOG in catalog.py (e.g., standalone_scan_complete, standalone_file_detected if used)
  </action>
  <verify>
```bash
cd backend && python -c "
from app import create_app
app = create_app(testing=True)
print('OK: App creates with event system initialized')
"

# Verify no remaining socketio.emit for business events (progress events are OK)
cd backend && grep -rn 'socketio\.emit' routes/ wanted_scanner.py whisper/queue.py standalone/__init__.py | grep -v '_progress\|job_update\|webhook_completed' || echo 'OK: All business events rewired'
```
  </verify>
  <done>All business-level socketio.emit calls replaced with emit_event; progress streams kept as direct socketio.emit; app.py initializes event system on startup; WebSocket backward compatibility maintained via bridge</done>
</task>

</tasks>

<verification>
1. `cd backend && python -c "from app import create_app; app = create_app(testing=True); print('OK')"` — app starts with event system
2. HookEngine can execute a simple shell script (e.g., `/bin/echo hello`) and capture output
3. WebhookDispatcher can send to a test URL (or mock) and handle retries
4. All completion/failure events use emit_event, progress events use direct socketio.emit
5. Frontend WebSocket still receives events (bridge working)
</verification>

<success_criteria>
- HookEngine executes shell scripts with controlled env, timeout, no shell=True, logs results
- WebhookDispatcher sends HTTP POST with HMAC, retry (2s/4s/8s backoff), logs results
- Both use ThreadPoolExecutor for async dispatch (never block event producer)
- All 22+ socketio.emit calls reviewed: business events rewired, progress streams kept
- app.py calls init_event_system during create_app
- Application starts without errors
- WebSocket clients still receive all events via bridge
</success_criteria>

<output>
After completion, create `.planning/phases/07-events-hooks-custom-scoring/07-02-SUMMARY.md`
</output>
