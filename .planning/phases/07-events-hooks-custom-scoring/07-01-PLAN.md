---
phase: 07-events-hooks-custom-scoring
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/events/__init__.py
  - backend/events/catalog.py
  - backend/db/__init__.py
  - backend/db/hooks.py
  - backend/db/scoring.py
  - backend/providers/base.py
autonomous: true

must_haves:
  truths:
    - "Internal events are published on a blinker event bus with a discoverable catalog of 14+ event types"
    - "Hook and webhook configurations can be stored and retrieved from the database"
    - "Hook execution log records can be stored and queried"
    - "Scoring weights are loaded from DB with fallback to hardcoded defaults"
    - "Per-provider score modifiers are applied during subtitle scoring"
    - "SocketIO bridge forwards all catalog events to WebSocket clients for backward compatibility"
  artifacts:
    - path: "backend/events/__init__.py"
      provides: "init_event_system function, SocketIO bridge registration"
      exports: ["init_event_system"]
    - path: "backend/events/catalog.py"
      provides: "blinker Namespace, named signals, EVENT_CATALOG dict"
      contains: "sublarr_signals"
    - path: "backend/db/hooks.py"
      provides: "CRUD for hook_configs, webhook_configs, hook_log tables"
      exports: ["create_hook_config", "get_hook_configs", "create_webhook_config", "get_webhook_configs", "log_hook_execution"]
    - path: "backend/db/scoring.py"
      provides: "CRUD for scoring_weights, provider_score_modifiers tables"
      exports: ["get_scoring_weights", "set_scoring_weights", "get_provider_modifier", "set_provider_modifier"]
    - path: "backend/providers/base.py"
      provides: "Modified compute_score using configurable weights from DB"
      contains: "get_scoring_weights"
  key_links:
    - from: "backend/events/catalog.py"
      to: "blinker.Namespace"
      via: "signal definition"
      pattern: "sublarr_signals\\.signal\\("
    - from: "backend/events/__init__.py"
      to: "backend/events/catalog.py"
      via: "import EVENT_CATALOG for bridge registration"
      pattern: "from events\\.catalog import"
    - from: "backend/providers/base.py"
      to: "backend/db/scoring.py"
      via: "lazy import for configurable weights"
      pattern: "from db\\.scoring import get_scoring_weights"
---

<objective>
Create the event bus foundation (blinker signals + catalog), database schema for hooks/webhooks/scoring (5 new tables), CRUD modules for all new tables, and wire configurable scoring weights into the existing compute_score function.

Purpose: This is the foundation for the entire phase. The event catalog defines what events exist, the DB schema stores hook/webhook/scoring configuration, and configurable scoring immediately delivers SCOR-01/SCOR-02 value. All subsequent plans (hook engine, webhook dispatcher, API routes, UI) depend on these artifacts.

Output: events/ package, db/hooks.py, db/scoring.py, modified providers/base.py, 5 new DB tables
</objective>

<execution_context>
@C:/Users/Dennis Wittke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dennis Wittke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-events-hooks-custom-scoring/07-RESEARCH.md

@backend/app.py
@backend/db/__init__.py
@backend/db/whisper.py
@backend/providers/base.py
@backend/extensions.py
@backend/notifier.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create events/ package with blinker catalog and SocketIO bridge</name>
  <files>backend/events/__init__.py, backend/events/catalog.py</files>
  <action>
Create `backend/events/` package with two files:

**catalog.py** — Define the canonical event catalog using blinker Namespace:
- Create `sublarr_signals = Namespace()` from blinker
- Define 14 named signals: `subtitle_downloaded`, `translation_complete`, `translation_failed`, `provider_search_complete`, `provider_failed`, `wanted_scan_complete`, `wanted_item_processed`, `upgrade_complete`, `batch_complete`, `webhook_received` (incoming *arr webhook), `config_updated`, `whisper_complete`, `whisper_failed`, `hook_executed` (meta-event)
- Create `EVENT_CATALOG` dict mapping event_name string -> dict with keys: `signal` (blinker Signal), `label` (human-readable), `description` (one-liner), `payload_keys` (list of strings describing safe-to-expose data fields)
- Payload keys must NOT include api_key, password, or raw file system paths — use relative paths or series/movie titles instead
- Include `version: 1` in the catalog metadata for future payload versioning

**__init__.py** — Provide `init_event_system(app)` function:
- Import EVENT_CATALOG from catalog.py
- Import socketio from extensions
- Register a SocketIO bridge subscriber for every event in EVENT_CATALOG: when any signal fires, emit the same event_name with the data dict to all WebSocket clients
- Use closure pattern (`def make_bridge(name)`) to correctly capture event_name in the loop
- Log at DEBUG level when bridge forwards an event
- Export `emit_event(event_name, data)` helper that looks up the signal in EVENT_CATALOG and calls `.send(current_app._get_current_object(), data=data)` — this is the primary API other modules will use
- Guard `current_app` import with try/except for use outside request context (fall back to None sender)
  </action>
  <verify>
```bash
cd backend && python -c "from events.catalog import sublarr_signals, EVENT_CATALOG; assert len(EVENT_CATALOG) >= 14; print(f'OK: {len(EVENT_CATALOG)} events defined')"
cd backend && python -c "from events import init_event_system, emit_event; print('OK: imports work')"
```
  </verify>
  <done>14+ events defined as blinker signals in a discoverable catalog; init_event_system registers SocketIO bridge; emit_event helper available for all modules</done>
</task>

<task type="auto">
  <name>Task 2: Add 5 new DB tables and CRUD modules for hooks and scoring</name>
  <files>backend/db/__init__.py, backend/db/hooks.py, backend/db/scoring.py</files>
  <action>
**db/__init__.py** — Add 5 new tables to the SCHEMA string (append after existing tables, before the closing triple-quote):

1. `hook_configs`: id (INTEGER PK AUTOINCREMENT), name (TEXT NOT NULL), event_name (TEXT NOT NULL), hook_type (TEXT DEFAULT 'script'), enabled (INTEGER DEFAULT 1), script_path (TEXT DEFAULT ''), timeout_seconds (INTEGER DEFAULT 30), last_triggered_at (TEXT DEFAULT ''), last_status (TEXT DEFAULT ''), trigger_count (INTEGER DEFAULT 0), created_at (TEXT NOT NULL DEFAULT datetime('now')), updated_at (TEXT NOT NULL DEFAULT datetime('now')). Index on event_name.

2. `webhook_configs`: id (INTEGER PK AUTOINCREMENT), name (TEXT NOT NULL), event_name (TEXT NOT NULL), url (TEXT NOT NULL), secret (TEXT DEFAULT ''), enabled (INTEGER DEFAULT 1), retry_count (INTEGER DEFAULT 3), timeout_seconds (INTEGER DEFAULT 10), last_triggered_at (TEXT DEFAULT ''), last_status_code (INTEGER DEFAULT 0), last_error (TEXT DEFAULT ''), consecutive_failures (INTEGER DEFAULT 0), trigger_count (INTEGER DEFAULT 0), created_at (TEXT NOT NULL DEFAULT datetime('now')), updated_at (TEXT NOT NULL DEFAULT datetime('now')). Index on event_name.

3. `hook_log`: id (INTEGER PK AUTOINCREMENT), hook_id (INTEGER), webhook_id (INTEGER), event_name (TEXT NOT NULL), hook_type (TEXT NOT NULL), success (INTEGER NOT NULL), exit_code (INTEGER DEFAULT NULL), status_code (INTEGER DEFAULT NULL), stdout (TEXT DEFAULT ''), stderr (TEXT DEFAULT ''), error (TEXT DEFAULT ''), duration_ms (REAL DEFAULT 0), triggered_at (TEXT NOT NULL DEFAULT datetime('now')). Indexes on hook_id, webhook_id, triggered_at.

4. `scoring_weights`: id (INTEGER PK AUTOINCREMENT), score_type (TEXT NOT NULL), weight_key (TEXT NOT NULL), weight_value (INTEGER NOT NULL), updated_at (TEXT NOT NULL DEFAULT datetime('now')), UNIQUE(score_type, weight_key).

5. `provider_score_modifiers`: provider_name (TEXT PRIMARY KEY), modifier (INTEGER NOT NULL DEFAULT 0), updated_at (TEXT NOT NULL DEFAULT datetime('now')).

**db/hooks.py** — CRUD following the _db_lock pattern from db/whisper.py:
- `create_hook_config(name, event_name, script_path, timeout_seconds=30)` -> dict
- `get_hook_configs(event_name=None)` -> list[dict] (optionally filter by event)
- `get_hook_config(hook_id)` -> dict or None
- `update_hook_config(hook_id, **kwargs)` -> None
- `delete_hook_config(hook_id)` -> None
- `create_webhook_config(name, event_name, url, secret="", retry_count=3, timeout_seconds=10)` -> dict
- `get_webhook_configs(event_name=None)` -> list[dict]
- `get_webhook_config(webhook_id)` -> dict or None
- `update_webhook_config(webhook_id, **kwargs)` -> None
- `delete_webhook_config(webhook_id)` -> None
- `log_hook_execution(hook_id=None, webhook_id=None, event_name="", hook_type="", success=False, exit_code=None, status_code=None, stdout="", stderr="", error="", duration_ms=0)` -> dict
- `get_hook_logs(hook_id=None, webhook_id=None, limit=50)` -> list[dict]
- `update_hook_trigger_stats(hook_id, success)` -> None (increment trigger_count, set last_triggered_at, last_status)
- `update_webhook_trigger_stats(webhook_id, success, status_code=0, error="")` -> None (increment trigger_count, track consecutive_failures, set last_triggered_at)

**db/scoring.py** — CRUD following the same pattern:
- `get_scoring_weights(score_type)` -> dict mapping weight_key -> weight_value. If no DB overrides exist, return empty dict (caller merges with defaults).
- `set_scoring_weights(score_type, weights_dict)` -> None. Uses INSERT OR REPLACE for each key-value pair.
- `get_all_scoring_weights()` -> dict with keys "episode" and "movie", each mapping to weight dicts (for UI display with defaults filled in)
- `reset_scoring_weights(score_type=None)` -> None. Deletes all rows (or for given type).
- `get_provider_modifier(provider_name)` -> int (returns 0 if not found)
- `get_all_provider_modifiers()` -> dict mapping provider_name -> modifier
- `set_provider_modifier(provider_name, modifier)` -> None. Uses INSERT OR REPLACE.
- `delete_provider_modifier(provider_name)` -> None
  </action>
  <verify>
```bash
cd backend && python -c "
from db import init_db, get_db
init_db()
db = get_db()
# Verify all 5 tables exist
tables = [r['name'] for r in db.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()]
for t in ['hook_configs', 'webhook_configs', 'hook_log', 'scoring_weights', 'provider_score_modifiers']:
    assert t in tables, f'Missing table: {t}'
print('OK: All 5 tables created')

from db.hooks import create_hook_config, get_hook_configs, create_webhook_config, get_webhook_configs, log_hook_execution
from db.scoring import get_scoring_weights, set_scoring_weights, get_provider_modifier, set_provider_modifier
h = create_hook_config('test', 'subtitle_downloaded', '/tmp/test.sh')
assert h['name'] == 'test'
w = create_webhook_config('test-wh', 'translation_complete', 'https://example.com/hook')
assert w['url'] == 'https://example.com/hook'
set_scoring_weights('episode', {'hash': 400})
weights = get_scoring_weights('episode')
assert weights.get('hash') == 400
set_provider_modifier('opensubtitles', -20)
assert get_provider_modifier('opensubtitles') == -20
print('OK: All CRUD operations work')
"
```
  </verify>
  <done>5 new tables in schema, db/hooks.py provides full CRUD for hook_configs + webhook_configs + hook_log, db/scoring.py provides CRUD for scoring_weights + provider_score_modifiers</done>
</task>

<task type="auto">
  <name>Task 3: Wire configurable scoring into compute_score</name>
  <files>backend/providers/base.py</files>
  <action>
Modify `compute_score()` in providers/base.py to use configurable weights from the database:

1. Add a module-level `_scoring_cache` dict with keys `data` (the weights dict) and `expires` (timestamp). TTL = 60 seconds.

2. Add `_get_cached_weights(score_type: str) -> dict` helper:
   - If cache is valid (not expired and score_type matches), return cached data
   - Otherwise: import `get_scoring_weights` from `db.scoring` (lazy import to avoid circular imports and to gracefully handle DB not initialized)
   - Wrap the import + call in try/except: if DB not available (e.g., during testing), return empty dict
   - Merge DB overrides on top of the hardcoded defaults (`EPISODE_SCORES` or `MOVIE_SCORES`): `{**defaults, **db_overrides}`
   - Cache the merged result with expiry timestamp
   - Return the merged dict

3. Add `_get_cached_modifier(provider_name: str) -> int` helper:
   - Similar cache pattern, separate cache dict `_modifier_cache` with TTL = 60 seconds
   - Lazy import `get_provider_modifier` from db.scoring
   - Return 0 on any exception

4. Modify `compute_score()`:
   - Replace `weights = EPISODE_SCORES if query.is_episode else MOVIE_SCORES` with `weights = _get_cached_weights("episode" if query.is_episode else "movie")`
   - After computing base score and ASS bonus, add: `modifier = _get_cached_modifier(result.provider_name)` and `score += modifier`
   - Set result.score = score and return score (unchanged logic, just uses configurable values)

5. Add `invalidate_scoring_cache()` function that clears both caches. This will be called by the config_updated event subscriber later.

Keep EPISODE_SCORES and MOVIE_SCORES as module-level constants (they serve as defaults and documentation).
  </action>
  <verify>
```bash
cd backend && python -c "
from providers.base import compute_score, SubtitleResult, VideoQuery, EPISODE_SCORES, invalidate_scoring_cache
# Test with defaults (no DB)
q = VideoQuery(series_title='Test', season=1, episode=1)
r = SubtitleResult(provider_name='test', subtitle_id='1', language='en', matches={'hash', 'series'})
score = compute_score(r, q)
expected = EPISODE_SCORES['hash'] + EPISODE_SCORES['series']
assert score == expected, f'Expected {expected}, got {score}'
print(f'OK: Default scoring works (score={score})')

# Test invalidation function exists
invalidate_scoring_cache()
print('OK: Cache invalidation works')
"
```
  </verify>
  <done>compute_score uses DB-configurable weights with 60s TTL cache, falls back to hardcoded defaults, applies per-provider modifiers, cache can be invalidated</done>
</task>

</tasks>

<verification>
1. `cd backend && python -c "from events.catalog import EVENT_CATALOG; print(len(EVENT_CATALOG), 'events')"` shows 14+
2. `cd backend && python -c "from events import init_event_system; print('OK')"` imports successfully
3. All 5 new tables exist in SQLite schema
4. db/hooks.py CRUD operations create/read/update/delete hook and webhook configs
5. db/scoring.py CRUD operations manage scoring weights and provider modifiers
6. compute_score returns correct scores with default weights when no DB overrides exist
7. compute_score applies DB weight overrides when they exist
</verification>

<success_criteria>
- events/catalog.py defines 14+ blinker signals with EVENT_CATALOG metadata dict
- events/__init__.py provides init_event_system (SocketIO bridge) and emit_event helper
- 5 new tables (hook_configs, webhook_configs, hook_log, scoring_weights, provider_score_modifiers) in schema
- db/hooks.py: full CRUD for hook_configs, webhook_configs, and hook_log
- db/scoring.py: full CRUD for scoring_weights and provider_score_modifiers
- compute_score reads configurable weights from DB with 60s cache, falls back to defaults
- Per-provider modifier applied in compute_score
- All existing tests continue to pass (no breaking changes)
</success_criteria>

<output>
After completion, create `.planning/phases/07-events-hooks-custom-scoring/07-01-SUMMARY.md`
</output>
